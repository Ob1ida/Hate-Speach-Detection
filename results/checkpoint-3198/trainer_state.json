{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 3198,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006253908692933083,
      "grad_norm": 4.291099548339844,
      "learning_rate": 4.989576818845112e-05,
      "loss": 0.0747,
      "step": 10
    },
    {
      "epoch": 0.012507817385866166,
      "grad_norm": 0.2860782742500305,
      "learning_rate": 4.979153637690223e-05,
      "loss": 0.2587,
      "step": 20
    },
    {
      "epoch": 0.01876172607879925,
      "grad_norm": 0.6768456101417542,
      "learning_rate": 4.9687304565353346e-05,
      "loss": 0.0483,
      "step": 30
    },
    {
      "epoch": 0.025015634771732333,
      "grad_norm": 5.607723712921143,
      "learning_rate": 4.958307275380447e-05,
      "loss": 0.0903,
      "step": 40
    },
    {
      "epoch": 0.031269543464665414,
      "grad_norm": 19.320632934570312,
      "learning_rate": 4.947884094225558e-05,
      "loss": 0.179,
      "step": 50
    },
    {
      "epoch": 0.0375234521575985,
      "grad_norm": 0.769263744354248,
      "learning_rate": 4.9374609130706695e-05,
      "loss": 0.1134,
      "step": 60
    },
    {
      "epoch": 0.043777360850531584,
      "grad_norm": 7.984750270843506,
      "learning_rate": 4.9270377319157805e-05,
      "loss": 0.1266,
      "step": 70
    },
    {
      "epoch": 0.050031269543464665,
      "grad_norm": 0.18168975412845612,
      "learning_rate": 4.916614550760892e-05,
      "loss": 0.083,
      "step": 80
    },
    {
      "epoch": 0.05628517823639775,
      "grad_norm": 3.23276686668396,
      "learning_rate": 4.906191369606004e-05,
      "loss": 0.0512,
      "step": 90
    },
    {
      "epoch": 0.06253908692933083,
      "grad_norm": 9.676409721374512,
      "learning_rate": 4.8957681884511155e-05,
      "loss": 0.0884,
      "step": 100
    },
    {
      "epoch": 0.06879299562226392,
      "grad_norm": 0.3160267174243927,
      "learning_rate": 4.885345007296227e-05,
      "loss": 0.0527,
      "step": 110
    },
    {
      "epoch": 0.075046904315197,
      "grad_norm": 4.140906810760498,
      "learning_rate": 4.874921826141339e-05,
      "loss": 0.0502,
      "step": 120
    },
    {
      "epoch": 0.08130081300813008,
      "grad_norm": 0.10053111612796783,
      "learning_rate": 4.86449864498645e-05,
      "loss": 0.0415,
      "step": 130
    },
    {
      "epoch": 0.08755472170106317,
      "grad_norm": 0.6729695796966553,
      "learning_rate": 4.8540754638315615e-05,
      "loss": 0.0658,
      "step": 140
    },
    {
      "epoch": 0.09380863039399624,
      "grad_norm": 0.06278358399868011,
      "learning_rate": 4.843652282676673e-05,
      "loss": 0.0435,
      "step": 150
    },
    {
      "epoch": 0.10006253908692933,
      "grad_norm": 0.6027106642723083,
      "learning_rate": 4.833229101521785e-05,
      "loss": 0.1804,
      "step": 160
    },
    {
      "epoch": 0.10631644777986242,
      "grad_norm": 1.0174719095230103,
      "learning_rate": 4.8228059203668965e-05,
      "loss": 0.1179,
      "step": 170
    },
    {
      "epoch": 0.1125703564727955,
      "grad_norm": 0.07532531768083572,
      "learning_rate": 4.812382739212008e-05,
      "loss": 0.0447,
      "step": 180
    },
    {
      "epoch": 0.11882426516572858,
      "grad_norm": 0.23015403747558594,
      "learning_rate": 4.801959558057119e-05,
      "loss": 0.1205,
      "step": 190
    },
    {
      "epoch": 0.12507817385866166,
      "grad_norm": 3.0194406509399414,
      "learning_rate": 4.791536376902231e-05,
      "loss": 0.0479,
      "step": 200
    },
    {
      "epoch": 0.13133208255159476,
      "grad_norm": 1.0671087503433228,
      "learning_rate": 4.781113195747342e-05,
      "loss": 0.0318,
      "step": 210
    },
    {
      "epoch": 0.13758599124452783,
      "grad_norm": 0.08635252714157104,
      "learning_rate": 4.770690014592454e-05,
      "loss": 0.1041,
      "step": 220
    },
    {
      "epoch": 0.1438398999374609,
      "grad_norm": 0.10599970817565918,
      "learning_rate": 4.760266833437566e-05,
      "loss": 0.0619,
      "step": 230
    },
    {
      "epoch": 0.150093808630394,
      "grad_norm": 6.836989402770996,
      "learning_rate": 4.749843652282677e-05,
      "loss": 0.1333,
      "step": 240
    },
    {
      "epoch": 0.15634771732332708,
      "grad_norm": 0.9700784087181091,
      "learning_rate": 4.7394204711277884e-05,
      "loss": 0.0907,
      "step": 250
    },
    {
      "epoch": 0.16260162601626016,
      "grad_norm": 0.1064070612192154,
      "learning_rate": 4.7289972899729e-05,
      "loss": 0.0971,
      "step": 260
    },
    {
      "epoch": 0.16885553470919323,
      "grad_norm": 11.843490600585938,
      "learning_rate": 4.718574108818011e-05,
      "loss": 0.0984,
      "step": 270
    },
    {
      "epoch": 0.17510944340212634,
      "grad_norm": 0.44960957765579224,
      "learning_rate": 4.708150927663123e-05,
      "loss": 0.0479,
      "step": 280
    },
    {
      "epoch": 0.1813633520950594,
      "grad_norm": 0.7914291024208069,
      "learning_rate": 4.697727746508235e-05,
      "loss": 0.0547,
      "step": 290
    },
    {
      "epoch": 0.18761726078799248,
      "grad_norm": 0.12643112242221832,
      "learning_rate": 4.687304565353346e-05,
      "loss": 0.0802,
      "step": 300
    },
    {
      "epoch": 0.1938711694809256,
      "grad_norm": 0.2583915889263153,
      "learning_rate": 4.676881384198458e-05,
      "loss": 0.1113,
      "step": 310
    },
    {
      "epoch": 0.20012507817385866,
      "grad_norm": 17.662296295166016,
      "learning_rate": 4.666458203043569e-05,
      "loss": 0.0262,
      "step": 320
    },
    {
      "epoch": 0.20637898686679174,
      "grad_norm": 7.00095796585083,
      "learning_rate": 4.6560350218886804e-05,
      "loss": 0.1184,
      "step": 330
    },
    {
      "epoch": 0.21263289555972484,
      "grad_norm": 0.14874887466430664,
      "learning_rate": 4.645611840733792e-05,
      "loss": 0.1073,
      "step": 340
    },
    {
      "epoch": 0.2188868042526579,
      "grad_norm": 6.306918144226074,
      "learning_rate": 4.635188659578904e-05,
      "loss": 0.0287,
      "step": 350
    },
    {
      "epoch": 0.225140712945591,
      "grad_norm": 0.20109951496124268,
      "learning_rate": 4.6247654784240154e-05,
      "loss": 0.0698,
      "step": 360
    },
    {
      "epoch": 0.2313946216385241,
      "grad_norm": 0.09608227014541626,
      "learning_rate": 4.614342297269127e-05,
      "loss": 0.0486,
      "step": 370
    },
    {
      "epoch": 0.23764853033145716,
      "grad_norm": 15.688694953918457,
      "learning_rate": 4.603919116114238e-05,
      "loss": 0.1249,
      "step": 380
    },
    {
      "epoch": 0.24390243902439024,
      "grad_norm": 9.634652137756348,
      "learning_rate": 4.59349593495935e-05,
      "loss": 0.0956,
      "step": 390
    },
    {
      "epoch": 0.2501563477173233,
      "grad_norm": 7.74387788772583,
      "learning_rate": 4.5830727538044614e-05,
      "loss": 0.111,
      "step": 400
    },
    {
      "epoch": 0.2564102564102564,
      "grad_norm": 13.138375282287598,
      "learning_rate": 4.572649572649573e-05,
      "loss": 0.1092,
      "step": 410
    },
    {
      "epoch": 0.2626641651031895,
      "grad_norm": 5.915304183959961,
      "learning_rate": 4.562226391494685e-05,
      "loss": 0.0953,
      "step": 420
    },
    {
      "epoch": 0.2689180737961226,
      "grad_norm": 6.373575210571289,
      "learning_rate": 4.5518032103397964e-05,
      "loss": 0.0574,
      "step": 430
    },
    {
      "epoch": 0.27517198248905567,
      "grad_norm": 6.757223606109619,
      "learning_rate": 4.541380029184907e-05,
      "loss": 0.0815,
      "step": 440
    },
    {
      "epoch": 0.28142589118198874,
      "grad_norm": 0.21939584612846375,
      "learning_rate": 4.530956848030019e-05,
      "loss": 0.0448,
      "step": 450
    },
    {
      "epoch": 0.2876797998749218,
      "grad_norm": 13.826632499694824,
      "learning_rate": 4.52053366687513e-05,
      "loss": 0.0575,
      "step": 460
    },
    {
      "epoch": 0.2939337085678549,
      "grad_norm": 10.636237144470215,
      "learning_rate": 4.5101104857202417e-05,
      "loss": 0.0768,
      "step": 470
    },
    {
      "epoch": 0.300187617260788,
      "grad_norm": 2.1250033378601074,
      "learning_rate": 4.499687304565354e-05,
      "loss": 0.1001,
      "step": 480
    },
    {
      "epoch": 0.3064415259537211,
      "grad_norm": 8.72056770324707,
      "learning_rate": 4.489264123410465e-05,
      "loss": 0.1731,
      "step": 490
    },
    {
      "epoch": 0.31269543464665417,
      "grad_norm": 7.16171932220459,
      "learning_rate": 4.4788409422555766e-05,
      "loss": 0.0986,
      "step": 500
    },
    {
      "epoch": 0.31894934333958724,
      "grad_norm": 0.383806049823761,
      "learning_rate": 4.468417761100688e-05,
      "loss": 0.0403,
      "step": 510
    },
    {
      "epoch": 0.3252032520325203,
      "grad_norm": 0.0500686839222908,
      "learning_rate": 4.457994579945799e-05,
      "loss": 0.062,
      "step": 520
    },
    {
      "epoch": 0.3314571607254534,
      "grad_norm": 9.560412406921387,
      "learning_rate": 4.447571398790911e-05,
      "loss": 0.1072,
      "step": 530
    },
    {
      "epoch": 0.33771106941838647,
      "grad_norm": 1.650088906288147,
      "learning_rate": 4.4371482176360226e-05,
      "loss": 0.1248,
      "step": 540
    },
    {
      "epoch": 0.3439649781113196,
      "grad_norm": 0.08336286246776581,
      "learning_rate": 4.426725036481134e-05,
      "loss": 0.0623,
      "step": 550
    },
    {
      "epoch": 0.35021888680425267,
      "grad_norm": 0.07596894353628159,
      "learning_rate": 4.416301855326246e-05,
      "loss": 0.0926,
      "step": 560
    },
    {
      "epoch": 0.35647279549718575,
      "grad_norm": 0.1307000368833542,
      "learning_rate": 4.4058786741713576e-05,
      "loss": 0.0637,
      "step": 570
    },
    {
      "epoch": 0.3627267041901188,
      "grad_norm": 0.733466386795044,
      "learning_rate": 4.3954554930164686e-05,
      "loss": 0.0177,
      "step": 580
    },
    {
      "epoch": 0.3689806128830519,
      "grad_norm": 0.17071810364723206,
      "learning_rate": 4.38503231186158e-05,
      "loss": 0.0699,
      "step": 590
    },
    {
      "epoch": 0.37523452157598497,
      "grad_norm": 5.092574596405029,
      "learning_rate": 4.374609130706692e-05,
      "loss": 0.0155,
      "step": 600
    },
    {
      "epoch": 0.3814884302689181,
      "grad_norm": 0.08063679188489914,
      "learning_rate": 4.3641859495518036e-05,
      "loss": 0.0213,
      "step": 610
    },
    {
      "epoch": 0.3877423389618512,
      "grad_norm": 0.08075270801782608,
      "learning_rate": 4.353762768396915e-05,
      "loss": 0.0526,
      "step": 620
    },
    {
      "epoch": 0.39399624765478425,
      "grad_norm": 1.1400920152664185,
      "learning_rate": 4.343339587242026e-05,
      "loss": 0.1074,
      "step": 630
    },
    {
      "epoch": 0.4002501563477173,
      "grad_norm": 5.785594463348389,
      "learning_rate": 4.332916406087138e-05,
      "loss": 0.0961,
      "step": 640
    },
    {
      "epoch": 0.4065040650406504,
      "grad_norm": 10.610084533691406,
      "learning_rate": 4.3224932249322496e-05,
      "loss": 0.1521,
      "step": 650
    },
    {
      "epoch": 0.41275797373358347,
      "grad_norm": 2.0674214363098145,
      "learning_rate": 4.312070043777361e-05,
      "loss": 0.039,
      "step": 660
    },
    {
      "epoch": 0.41901188242651655,
      "grad_norm": 0.42433595657348633,
      "learning_rate": 4.301646862622473e-05,
      "loss": 0.0563,
      "step": 670
    },
    {
      "epoch": 0.4252657911194497,
      "grad_norm": 0.4235002100467682,
      "learning_rate": 4.2912236814675846e-05,
      "loss": 0.1504,
      "step": 680
    },
    {
      "epoch": 0.43151969981238275,
      "grad_norm": 0.1293834149837494,
      "learning_rate": 4.2808005003126955e-05,
      "loss": 0.0292,
      "step": 690
    },
    {
      "epoch": 0.4377736085053158,
      "grad_norm": 12.587324142456055,
      "learning_rate": 4.270377319157807e-05,
      "loss": 0.0792,
      "step": 700
    },
    {
      "epoch": 0.4440275171982489,
      "grad_norm": 0.18624401092529297,
      "learning_rate": 4.259954138002918e-05,
      "loss": 0.0872,
      "step": 710
    },
    {
      "epoch": 0.450281425891182,
      "grad_norm": 1.7729555368423462,
      "learning_rate": 4.24953095684803e-05,
      "loss": 0.0108,
      "step": 720
    },
    {
      "epoch": 0.45653533458411505,
      "grad_norm": 0.0633101537823677,
      "learning_rate": 4.239107775693142e-05,
      "loss": 0.0961,
      "step": 730
    },
    {
      "epoch": 0.4627892432770482,
      "grad_norm": 0.6789349913597107,
      "learning_rate": 4.228684594538253e-05,
      "loss": 0.0329,
      "step": 740
    },
    {
      "epoch": 0.46904315196998125,
      "grad_norm": 0.7463671565055847,
      "learning_rate": 4.218261413383365e-05,
      "loss": 0.0249,
      "step": 750
    },
    {
      "epoch": 0.47529706066291433,
      "grad_norm": 2.6279168128967285,
      "learning_rate": 4.2078382322284765e-05,
      "loss": 0.0044,
      "step": 760
    },
    {
      "epoch": 0.4815509693558474,
      "grad_norm": 0.03604523092508316,
      "learning_rate": 4.1974150510735875e-05,
      "loss": 0.0782,
      "step": 770
    },
    {
      "epoch": 0.4878048780487805,
      "grad_norm": 0.036616433411836624,
      "learning_rate": 4.186991869918699e-05,
      "loss": 0.1576,
      "step": 780
    },
    {
      "epoch": 0.49405878674171355,
      "grad_norm": 0.09100951999425888,
      "learning_rate": 4.176568688763811e-05,
      "loss": 0.0281,
      "step": 790
    },
    {
      "epoch": 0.5003126954346466,
      "grad_norm": 0.057935066521167755,
      "learning_rate": 4.1661455076089225e-05,
      "loss": 0.0658,
      "step": 800
    },
    {
      "epoch": 0.5065666041275797,
      "grad_norm": 8.132308959960938,
      "learning_rate": 4.155722326454034e-05,
      "loss": 0.0739,
      "step": 810
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 0.1469096690416336,
      "learning_rate": 4.145299145299146e-05,
      "loss": 0.1112,
      "step": 820
    },
    {
      "epoch": 0.5190744215134458,
      "grad_norm": 6.589786529541016,
      "learning_rate": 4.134875964144257e-05,
      "loss": 0.0727,
      "step": 830
    },
    {
      "epoch": 0.525328330206379,
      "grad_norm": 1.3200281858444214,
      "learning_rate": 4.1244527829893685e-05,
      "loss": 0.0436,
      "step": 840
    },
    {
      "epoch": 0.5315822388993121,
      "grad_norm": 28.305082321166992,
      "learning_rate": 4.11402960183448e-05,
      "loss": 0.0842,
      "step": 850
    },
    {
      "epoch": 0.5378361475922452,
      "grad_norm": 0.06538552790880203,
      "learning_rate": 4.103606420679592e-05,
      "loss": 0.092,
      "step": 860
    },
    {
      "epoch": 0.5440900562851783,
      "grad_norm": 0.14088158309459686,
      "learning_rate": 4.0931832395247035e-05,
      "loss": 0.0598,
      "step": 870
    },
    {
      "epoch": 0.5503439649781113,
      "grad_norm": 0.06562728434801102,
      "learning_rate": 4.0827600583698144e-05,
      "loss": 0.1129,
      "step": 880
    },
    {
      "epoch": 0.5565978736710444,
      "grad_norm": 1.05733323097229,
      "learning_rate": 4.072336877214926e-05,
      "loss": 0.0669,
      "step": 890
    },
    {
      "epoch": 0.5628517823639775,
      "grad_norm": 17.93256378173828,
      "learning_rate": 4.061913696060038e-05,
      "loss": 0.0912,
      "step": 900
    },
    {
      "epoch": 0.5691056910569106,
      "grad_norm": 9.491959571838379,
      "learning_rate": 4.051490514905149e-05,
      "loss": 0.0403,
      "step": 910
    },
    {
      "epoch": 0.5753595997498436,
      "grad_norm": 0.04010415077209473,
      "learning_rate": 4.041067333750261e-05,
      "loss": 0.1284,
      "step": 920
    },
    {
      "epoch": 0.5816135084427767,
      "grad_norm": 0.06082770228385925,
      "learning_rate": 4.030644152595373e-05,
      "loss": 0.164,
      "step": 930
    },
    {
      "epoch": 0.5878674171357098,
      "grad_norm": 0.09021168947219849,
      "learning_rate": 4.020220971440484e-05,
      "loss": 0.0896,
      "step": 940
    },
    {
      "epoch": 0.5941213258286429,
      "grad_norm": 1.4429004192352295,
      "learning_rate": 4.0097977902855954e-05,
      "loss": 0.0791,
      "step": 950
    },
    {
      "epoch": 0.600375234521576,
      "grad_norm": 2.4441921710968018,
      "learning_rate": 3.9993746091307064e-05,
      "loss": 0.049,
      "step": 960
    },
    {
      "epoch": 0.6066291432145091,
      "grad_norm": 15.107951164245605,
      "learning_rate": 3.988951427975818e-05,
      "loss": 0.1308,
      "step": 970
    },
    {
      "epoch": 0.6128830519074422,
      "grad_norm": 7.791202068328857,
      "learning_rate": 3.9785282468209304e-05,
      "loss": 0.0437,
      "step": 980
    },
    {
      "epoch": 0.6191369606003753,
      "grad_norm": 3.442681074142456,
      "learning_rate": 3.9681050656660414e-05,
      "loss": 0.0486,
      "step": 990
    },
    {
      "epoch": 0.6253908692933083,
      "grad_norm": 4.004490375518799,
      "learning_rate": 3.957681884511153e-05,
      "loss": 0.0297,
      "step": 1000
    },
    {
      "epoch": 0.6316447779862414,
      "grad_norm": 0.11028594523668289,
      "learning_rate": 3.947258703356265e-05,
      "loss": 0.0108,
      "step": 1010
    },
    {
      "epoch": 0.6378986866791745,
      "grad_norm": 0.06608215719461441,
      "learning_rate": 3.936835522201376e-05,
      "loss": 0.0531,
      "step": 1020
    },
    {
      "epoch": 0.6441525953721076,
      "grad_norm": 0.042441170662641525,
      "learning_rate": 3.9264123410464874e-05,
      "loss": 0.1287,
      "step": 1030
    },
    {
      "epoch": 0.6504065040650406,
      "grad_norm": 0.04160606116056442,
      "learning_rate": 3.915989159891599e-05,
      "loss": 0.0392,
      "step": 1040
    },
    {
      "epoch": 0.6566604127579737,
      "grad_norm": 0.11635306477546692,
      "learning_rate": 3.905565978736711e-05,
      "loss": 0.1194,
      "step": 1050
    },
    {
      "epoch": 0.6629143214509068,
      "grad_norm": 0.27154430747032166,
      "learning_rate": 3.8951427975818223e-05,
      "loss": 0.0414,
      "step": 1060
    },
    {
      "epoch": 0.6691682301438399,
      "grad_norm": 0.038260530680418015,
      "learning_rate": 3.884719616426934e-05,
      "loss": 0.0441,
      "step": 1070
    },
    {
      "epoch": 0.6754221388367729,
      "grad_norm": 0.08210691809654236,
      "learning_rate": 3.874296435272045e-05,
      "loss": 0.043,
      "step": 1080
    },
    {
      "epoch": 0.6816760475297061,
      "grad_norm": 0.04930547624826431,
      "learning_rate": 3.863873254117157e-05,
      "loss": 0.1496,
      "step": 1090
    },
    {
      "epoch": 0.6879299562226392,
      "grad_norm": 27.380029678344727,
      "learning_rate": 3.853450072962268e-05,
      "loss": 0.1203,
      "step": 1100
    },
    {
      "epoch": 0.6941838649155723,
      "grad_norm": 0.049737993627786636,
      "learning_rate": 3.84302689180738e-05,
      "loss": 0.0439,
      "step": 1110
    },
    {
      "epoch": 0.7004377736085053,
      "grad_norm": 0.6220563650131226,
      "learning_rate": 3.8326037106524917e-05,
      "loss": 0.0214,
      "step": 1120
    },
    {
      "epoch": 0.7066916823014384,
      "grad_norm": 0.05965579301118851,
      "learning_rate": 3.8221805294976026e-05,
      "loss": 0.0235,
      "step": 1130
    },
    {
      "epoch": 0.7129455909943715,
      "grad_norm": 0.06679427623748779,
      "learning_rate": 3.811757348342714e-05,
      "loss": 0.0392,
      "step": 1140
    },
    {
      "epoch": 0.7191994996873046,
      "grad_norm": 1.7009018659591675,
      "learning_rate": 3.801334167187826e-05,
      "loss": 0.0392,
      "step": 1150
    },
    {
      "epoch": 0.7254534083802376,
      "grad_norm": 0.6108495593070984,
      "learning_rate": 3.790910986032937e-05,
      "loss": 0.1139,
      "step": 1160
    },
    {
      "epoch": 0.7317073170731707,
      "grad_norm": 0.031215891242027283,
      "learning_rate": 3.780487804878049e-05,
      "loss": 0.1591,
      "step": 1170
    },
    {
      "epoch": 0.7379612257661038,
      "grad_norm": 0.11882312595844269,
      "learning_rate": 3.770064623723161e-05,
      "loss": 0.0524,
      "step": 1180
    },
    {
      "epoch": 0.7442151344590369,
      "grad_norm": 0.036917008459568024,
      "learning_rate": 3.759641442568272e-05,
      "loss": 0.0535,
      "step": 1190
    },
    {
      "epoch": 0.7504690431519699,
      "grad_norm": 3.584357738494873,
      "learning_rate": 3.7492182614133836e-05,
      "loss": 0.0279,
      "step": 1200
    },
    {
      "epoch": 0.756722951844903,
      "grad_norm": 0.03357454016804695,
      "learning_rate": 3.738795080258495e-05,
      "loss": 0.0858,
      "step": 1210
    },
    {
      "epoch": 0.7629768605378362,
      "grad_norm": 10.675154685974121,
      "learning_rate": 3.728371899103606e-05,
      "loss": 0.027,
      "step": 1220
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 0.04237139970064163,
      "learning_rate": 3.717948717948718e-05,
      "loss": 0.0386,
      "step": 1230
    },
    {
      "epoch": 0.7754846779237023,
      "grad_norm": 0.10772591829299927,
      "learning_rate": 3.7075255367938296e-05,
      "loss": 0.0495,
      "step": 1240
    },
    {
      "epoch": 0.7817385866166354,
      "grad_norm": 11.118101119995117,
      "learning_rate": 3.697102355638941e-05,
      "loss": 0.0424,
      "step": 1250
    },
    {
      "epoch": 0.7879924953095685,
      "grad_norm": 0.10572243481874466,
      "learning_rate": 3.686679174484053e-05,
      "loss": 0.0649,
      "step": 1260
    },
    {
      "epoch": 0.7942464040025016,
      "grad_norm": 0.027645647525787354,
      "learning_rate": 3.676255993329164e-05,
      "loss": 0.0422,
      "step": 1270
    },
    {
      "epoch": 0.8005003126954346,
      "grad_norm": 7.8873701095581055,
      "learning_rate": 3.6658328121742756e-05,
      "loss": 0.0951,
      "step": 1280
    },
    {
      "epoch": 0.8067542213883677,
      "grad_norm": 0.042448740452528,
      "learning_rate": 3.655409631019387e-05,
      "loss": 0.034,
      "step": 1290
    },
    {
      "epoch": 0.8130081300813008,
      "grad_norm": 0.08420506864786148,
      "learning_rate": 3.644986449864499e-05,
      "loss": 0.0791,
      "step": 1300
    },
    {
      "epoch": 0.8192620387742339,
      "grad_norm": 0.03296882286667824,
      "learning_rate": 3.6345632687096105e-05,
      "loss": 0.117,
      "step": 1310
    },
    {
      "epoch": 0.8255159474671669,
      "grad_norm": 3.50466251373291,
      "learning_rate": 3.624140087554722e-05,
      "loss": 0.0587,
      "step": 1320
    },
    {
      "epoch": 0.8317698561601,
      "grad_norm": 11.576956748962402,
      "learning_rate": 3.613716906399833e-05,
      "loss": 0.0512,
      "step": 1330
    },
    {
      "epoch": 0.8380237648530331,
      "grad_norm": 0.04870525747537613,
      "learning_rate": 3.603293725244945e-05,
      "loss": 0.1568,
      "step": 1340
    },
    {
      "epoch": 0.8442776735459663,
      "grad_norm": 3.14689040184021,
      "learning_rate": 3.5928705440900565e-05,
      "loss": 0.1214,
      "step": 1350
    },
    {
      "epoch": 0.8505315822388994,
      "grad_norm": 17.910242080688477,
      "learning_rate": 3.582447362935168e-05,
      "loss": 0.1309,
      "step": 1360
    },
    {
      "epoch": 0.8567854909318324,
      "grad_norm": 12.026419639587402,
      "learning_rate": 3.57202418178028e-05,
      "loss": 0.0563,
      "step": 1370
    },
    {
      "epoch": 0.8630393996247655,
      "grad_norm": 0.07085279375314713,
      "learning_rate": 3.561601000625391e-05,
      "loss": 0.0408,
      "step": 1380
    },
    {
      "epoch": 0.8692933083176986,
      "grad_norm": 1.008329153060913,
      "learning_rate": 3.5511778194705025e-05,
      "loss": 0.079,
      "step": 1390
    },
    {
      "epoch": 0.8755472170106317,
      "grad_norm": 10.595829010009766,
      "learning_rate": 3.540754638315614e-05,
      "loss": 0.0969,
      "step": 1400
    },
    {
      "epoch": 0.8818011257035647,
      "grad_norm": 19.474098205566406,
      "learning_rate": 3.530331457160725e-05,
      "loss": 0.0129,
      "step": 1410
    },
    {
      "epoch": 0.8880550343964978,
      "grad_norm": 6.5079345703125,
      "learning_rate": 3.5199082760058375e-05,
      "loss": 0.0937,
      "step": 1420
    },
    {
      "epoch": 0.8943089430894309,
      "grad_norm": 0.10278644412755966,
      "learning_rate": 3.509485094850949e-05,
      "loss": 0.0609,
      "step": 1430
    },
    {
      "epoch": 0.900562851782364,
      "grad_norm": 0.3874758780002594,
      "learning_rate": 3.49906191369606e-05,
      "loss": 0.0434,
      "step": 1440
    },
    {
      "epoch": 0.906816760475297,
      "grad_norm": 5.10392427444458,
      "learning_rate": 3.488638732541172e-05,
      "loss": 0.0733,
      "step": 1450
    },
    {
      "epoch": 0.9130706691682301,
      "grad_norm": 0.3235251009464264,
      "learning_rate": 3.4782155513862835e-05,
      "loss": 0.1076,
      "step": 1460
    },
    {
      "epoch": 0.9193245778611632,
      "grad_norm": 0.0452614426612854,
      "learning_rate": 3.4677923702313945e-05,
      "loss": 0.0793,
      "step": 1470
    },
    {
      "epoch": 0.9255784865540964,
      "grad_norm": 12.353853225708008,
      "learning_rate": 3.457369189076506e-05,
      "loss": 0.1126,
      "step": 1480
    },
    {
      "epoch": 0.9318323952470294,
      "grad_norm": 0.21806354820728302,
      "learning_rate": 3.446946007921618e-05,
      "loss": 0.2261,
      "step": 1490
    },
    {
      "epoch": 0.9380863039399625,
      "grad_norm": 0.08168236911296844,
      "learning_rate": 3.4365228267667294e-05,
      "loss": 0.0961,
      "step": 1500
    },
    {
      "epoch": 0.9443402126328956,
      "grad_norm": 0.2565726637840271,
      "learning_rate": 3.426099645611841e-05,
      "loss": 0.0525,
      "step": 1510
    },
    {
      "epoch": 0.9505941213258287,
      "grad_norm": 9.767847061157227,
      "learning_rate": 3.415676464456952e-05,
      "loss": 0.0738,
      "step": 1520
    },
    {
      "epoch": 0.9568480300187617,
      "grad_norm": 5.232820987701416,
      "learning_rate": 3.405253283302064e-05,
      "loss": 0.0772,
      "step": 1530
    },
    {
      "epoch": 0.9631019387116948,
      "grad_norm": 1.5355411767959595,
      "learning_rate": 3.3948301021471754e-05,
      "loss": 0.0607,
      "step": 1540
    },
    {
      "epoch": 0.9693558474046279,
      "grad_norm": 2.879824161529541,
      "learning_rate": 3.384406920992287e-05,
      "loss": 0.0422,
      "step": 1550
    },
    {
      "epoch": 0.975609756097561,
      "grad_norm": 0.21715925633907318,
      "learning_rate": 3.373983739837399e-05,
      "loss": 0.0562,
      "step": 1560
    },
    {
      "epoch": 0.981863664790494,
      "grad_norm": 14.328224182128906,
      "learning_rate": 3.3635605586825104e-05,
      "loss": 0.1179,
      "step": 1570
    },
    {
      "epoch": 0.9881175734834271,
      "grad_norm": 0.6427140831947327,
      "learning_rate": 3.3531373775276214e-05,
      "loss": 0.0759,
      "step": 1580
    },
    {
      "epoch": 0.9943714821763602,
      "grad_norm": 0.0810517817735672,
      "learning_rate": 3.342714196372733e-05,
      "loss": 0.0688,
      "step": 1590
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9576098858126075,
      "eval_loss": 0.16604188084602356,
      "eval_runtime": 9.6112,
      "eval_samples_per_second": 665.163,
      "eval_steps_per_second": 41.618,
      "step": 1599
    },
    {
      "epoch": 1.0006253908692933,
      "grad_norm": 0.32042133808135986,
      "learning_rate": 3.332291015217844e-05,
      "loss": 0.1593,
      "step": 1600
    },
    {
      "epoch": 1.0068792995622264,
      "grad_norm": 2.5184946060180664,
      "learning_rate": 3.3218678340629564e-05,
      "loss": 0.1122,
      "step": 1610
    },
    {
      "epoch": 1.0131332082551594,
      "grad_norm": 10.624920845031738,
      "learning_rate": 3.311444652908068e-05,
      "loss": 0.1281,
      "step": 1620
    },
    {
      "epoch": 1.0193871169480926,
      "grad_norm": 0.062354687601327896,
      "learning_rate": 3.301021471753179e-05,
      "loss": 0.0849,
      "step": 1630
    },
    {
      "epoch": 1.0256410256410255,
      "grad_norm": 5.642749786376953,
      "learning_rate": 3.290598290598291e-05,
      "loss": 0.0417,
      "step": 1640
    },
    {
      "epoch": 1.0318949343339587,
      "grad_norm": 26.59457015991211,
      "learning_rate": 3.2801751094434024e-05,
      "loss": 0.0696,
      "step": 1650
    },
    {
      "epoch": 1.038148843026892,
      "grad_norm": 0.20067228376865387,
      "learning_rate": 3.2697519282885134e-05,
      "loss": 0.14,
      "step": 1660
    },
    {
      "epoch": 1.0444027517198249,
      "grad_norm": 0.05937497690320015,
      "learning_rate": 3.259328747133625e-05,
      "loss": 0.0187,
      "step": 1670
    },
    {
      "epoch": 1.050656660412758,
      "grad_norm": 0.08108001202344894,
      "learning_rate": 3.2489055659787374e-05,
      "loss": 0.0219,
      "step": 1680
    },
    {
      "epoch": 1.056910569105691,
      "grad_norm": 8.420589447021484,
      "learning_rate": 3.2384823848238483e-05,
      "loss": 0.0601,
      "step": 1690
    },
    {
      "epoch": 1.0631644777986242,
      "grad_norm": 0.5731619596481323,
      "learning_rate": 3.22805920366896e-05,
      "loss": 0.1324,
      "step": 1700
    },
    {
      "epoch": 1.0694183864915572,
      "grad_norm": 26.9782772064209,
      "learning_rate": 3.217636022514072e-05,
      "loss": 0.0647,
      "step": 1710
    },
    {
      "epoch": 1.0756722951844904,
      "grad_norm": 0.07661382853984833,
      "learning_rate": 3.2072128413591827e-05,
      "loss": 0.061,
      "step": 1720
    },
    {
      "epoch": 1.0819262038774233,
      "grad_norm": 0.06333530694246292,
      "learning_rate": 3.196789660204294e-05,
      "loss": 0.1536,
      "step": 1730
    },
    {
      "epoch": 1.0881801125703565,
      "grad_norm": 8.301142692565918,
      "learning_rate": 3.186366479049406e-05,
      "loss": 0.1139,
      "step": 1740
    },
    {
      "epoch": 1.0944340212632895,
      "grad_norm": 14.34422492980957,
      "learning_rate": 3.1759432978945176e-05,
      "loss": 0.1253,
      "step": 1750
    },
    {
      "epoch": 1.1006879299562227,
      "grad_norm": 0.8462964296340942,
      "learning_rate": 3.165520116739629e-05,
      "loss": 0.056,
      "step": 1760
    },
    {
      "epoch": 1.1069418386491556,
      "grad_norm": 0.1978406012058258,
      "learning_rate": 3.15509693558474e-05,
      "loss": 0.0377,
      "step": 1770
    },
    {
      "epoch": 1.1131957473420888,
      "grad_norm": 0.04828416183590889,
      "learning_rate": 3.144673754429852e-05,
      "loss": 0.0196,
      "step": 1780
    },
    {
      "epoch": 1.1194496560350218,
      "grad_norm": 0.09661304950714111,
      "learning_rate": 3.1342505732749636e-05,
      "loss": 0.0971,
      "step": 1790
    },
    {
      "epoch": 1.125703564727955,
      "grad_norm": 12.195548057556152,
      "learning_rate": 3.123827392120075e-05,
      "loss": 0.08,
      "step": 1800
    },
    {
      "epoch": 1.1319574734208881,
      "grad_norm": 0.1276957392692566,
      "learning_rate": 3.113404210965187e-05,
      "loss": 0.1639,
      "step": 1810
    },
    {
      "epoch": 1.1382113821138211,
      "grad_norm": 19.64949607849121,
      "learning_rate": 3.1029810298102986e-05,
      "loss": 0.0743,
      "step": 1820
    },
    {
      "epoch": 1.1444652908067543,
      "grad_norm": 0.593393862247467,
      "learning_rate": 3.0925578486554096e-05,
      "loss": 0.1215,
      "step": 1830
    },
    {
      "epoch": 1.1507191994996873,
      "grad_norm": 13.246689796447754,
      "learning_rate": 3.082134667500521e-05,
      "loss": 0.0308,
      "step": 1840
    },
    {
      "epoch": 1.1569731081926204,
      "grad_norm": 5.691676139831543,
      "learning_rate": 3.071711486345633e-05,
      "loss": 0.0243,
      "step": 1850
    },
    {
      "epoch": 1.1632270168855534,
      "grad_norm": 0.06832911819219589,
      "learning_rate": 3.0612883051907446e-05,
      "loss": 0.0503,
      "step": 1860
    },
    {
      "epoch": 1.1694809255784866,
      "grad_norm": 13.110079765319824,
      "learning_rate": 3.050865124035856e-05,
      "loss": 0.1,
      "step": 1870
    },
    {
      "epoch": 1.1757348342714196,
      "grad_norm": 2.8341612815856934,
      "learning_rate": 3.0404419428809672e-05,
      "loss": 0.0827,
      "step": 1880
    },
    {
      "epoch": 1.1819887429643527,
      "grad_norm": 0.6595374345779419,
      "learning_rate": 3.030018761726079e-05,
      "loss": 0.0711,
      "step": 1890
    },
    {
      "epoch": 1.1882426516572857,
      "grad_norm": 1.1508363485336304,
      "learning_rate": 3.0195955805711906e-05,
      "loss": 0.2097,
      "step": 1900
    },
    {
      "epoch": 1.194496560350219,
      "grad_norm": 4.438155174255371,
      "learning_rate": 3.009172399416302e-05,
      "loss": 0.1382,
      "step": 1910
    },
    {
      "epoch": 1.200750469043152,
      "grad_norm": 0.12433652579784393,
      "learning_rate": 2.9987492182614136e-05,
      "loss": 0.0361,
      "step": 1920
    },
    {
      "epoch": 1.207004377736085,
      "grad_norm": 0.2939240336418152,
      "learning_rate": 2.9883260371065252e-05,
      "loss": 0.043,
      "step": 1930
    },
    {
      "epoch": 1.2132582864290182,
      "grad_norm": 0.09291815012693405,
      "learning_rate": 2.9779028559516365e-05,
      "loss": 0.0546,
      "step": 1940
    },
    {
      "epoch": 1.2195121951219512,
      "grad_norm": 1.5200806856155396,
      "learning_rate": 2.9674796747967482e-05,
      "loss": 0.0523,
      "step": 1950
    },
    {
      "epoch": 1.2257661038148844,
      "grad_norm": 0.20449618995189667,
      "learning_rate": 2.95705649364186e-05,
      "loss": 0.0215,
      "step": 1960
    },
    {
      "epoch": 1.2320200125078173,
      "grad_norm": 0.24836504459381104,
      "learning_rate": 2.9466333124869712e-05,
      "loss": 0.0488,
      "step": 1970
    },
    {
      "epoch": 1.2382739212007505,
      "grad_norm": 0.1387498527765274,
      "learning_rate": 2.936210131332083e-05,
      "loss": 0.0138,
      "step": 1980
    },
    {
      "epoch": 1.2445278298936835,
      "grad_norm": 0.2314121425151825,
      "learning_rate": 2.925786950177194e-05,
      "loss": 0.0547,
      "step": 1990
    },
    {
      "epoch": 1.2507817385866167,
      "grad_norm": 0.7722101211547852,
      "learning_rate": 2.915363769022306e-05,
      "loss": 0.0865,
      "step": 2000
    },
    {
      "epoch": 1.2570356472795496,
      "grad_norm": 17.089645385742188,
      "learning_rate": 2.9049405878674175e-05,
      "loss": 0.0973,
      "step": 2010
    },
    {
      "epoch": 1.2632895559724828,
      "grad_norm": 0.08141427487134933,
      "learning_rate": 2.8945174067125285e-05,
      "loss": 0.1037,
      "step": 2020
    },
    {
      "epoch": 1.269543464665416,
      "grad_norm": 0.2173476368188858,
      "learning_rate": 2.88409422555764e-05,
      "loss": 0.1795,
      "step": 2030
    },
    {
      "epoch": 1.275797373358349,
      "grad_norm": 9.99531078338623,
      "learning_rate": 2.873671044402752e-05,
      "loss": 0.1217,
      "step": 2040
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 0.15267162024974823,
      "learning_rate": 2.863247863247863e-05,
      "loss": 0.0429,
      "step": 2050
    },
    {
      "epoch": 1.2883051907442151,
      "grad_norm": 1.171288251876831,
      "learning_rate": 2.8528246820929748e-05,
      "loss": 0.05,
      "step": 2060
    },
    {
      "epoch": 1.2945590994371483,
      "grad_norm": 0.09460505098104477,
      "learning_rate": 2.8424015009380868e-05,
      "loss": 0.091,
      "step": 2070
    },
    {
      "epoch": 1.3008130081300813,
      "grad_norm": 16.638790130615234,
      "learning_rate": 2.8319783197831978e-05,
      "loss": 0.0523,
      "step": 2080
    },
    {
      "epoch": 1.3070669168230145,
      "grad_norm": 7.1604485511779785,
      "learning_rate": 2.8215551386283095e-05,
      "loss": 0.0865,
      "step": 2090
    },
    {
      "epoch": 1.3133208255159474,
      "grad_norm": 11.513717651367188,
      "learning_rate": 2.811131957473421e-05,
      "loss": 0.0726,
      "step": 2100
    },
    {
      "epoch": 1.3195747342088806,
      "grad_norm": 2.8481638431549072,
      "learning_rate": 2.8007087763185325e-05,
      "loss": 0.055,
      "step": 2110
    },
    {
      "epoch": 1.3258286429018136,
      "grad_norm": 0.1423216015100479,
      "learning_rate": 2.790285595163644e-05,
      "loss": 0.079,
      "step": 2120
    },
    {
      "epoch": 1.3320825515947468,
      "grad_norm": 0.5904778838157654,
      "learning_rate": 2.7798624140087554e-05,
      "loss": 0.0432,
      "step": 2130
    },
    {
      "epoch": 1.3383364602876797,
      "grad_norm": 9.761795043945312,
      "learning_rate": 2.769439232853867e-05,
      "loss": 0.079,
      "step": 2140
    },
    {
      "epoch": 1.344590368980613,
      "grad_norm": 13.438176155090332,
      "learning_rate": 2.7590160516989788e-05,
      "loss": 0.0609,
      "step": 2150
    },
    {
      "epoch": 1.3508442776735459,
      "grad_norm": 0.9065282940864563,
      "learning_rate": 2.74859287054409e-05,
      "loss": 0.0742,
      "step": 2160
    },
    {
      "epoch": 1.357098186366479,
      "grad_norm": 0.3811419606208801,
      "learning_rate": 2.7381696893892018e-05,
      "loss": 0.1315,
      "step": 2170
    },
    {
      "epoch": 1.3633520950594122,
      "grad_norm": 13.05263614654541,
      "learning_rate": 2.7277465082343134e-05,
      "loss": 0.114,
      "step": 2180
    },
    {
      "epoch": 1.3696060037523452,
      "grad_norm": 10.256935119628906,
      "learning_rate": 2.7173233270794247e-05,
      "loss": 0.1616,
      "step": 2190
    },
    {
      "epoch": 1.3758599124452782,
      "grad_norm": 26.4405517578125,
      "learning_rate": 2.7069001459245364e-05,
      "loss": 0.0217,
      "step": 2200
    },
    {
      "epoch": 1.3821138211382114,
      "grad_norm": 8.960905075073242,
      "learning_rate": 2.696476964769648e-05,
      "loss": 0.1465,
      "step": 2210
    },
    {
      "epoch": 1.3883677298311445,
      "grad_norm": 0.05003197118639946,
      "learning_rate": 2.6860537836147594e-05,
      "loss": 0.0872,
      "step": 2220
    },
    {
      "epoch": 1.3946216385240775,
      "grad_norm": 1.9361681938171387,
      "learning_rate": 2.675630602459871e-05,
      "loss": 0.1829,
      "step": 2230
    },
    {
      "epoch": 1.4008755472170107,
      "grad_norm": 0.058499790728092194,
      "learning_rate": 2.665207421304982e-05,
      "loss": 0.0687,
      "step": 2240
    },
    {
      "epoch": 1.4071294559099436,
      "grad_norm": 0.05791311711072922,
      "learning_rate": 2.6547842401500937e-05,
      "loss": 0.1161,
      "step": 2250
    },
    {
      "epoch": 1.4133833646028768,
      "grad_norm": 0.1257210224866867,
      "learning_rate": 2.6443610589952057e-05,
      "loss": 0.0764,
      "step": 2260
    },
    {
      "epoch": 1.4196372732958098,
      "grad_norm": 15.215116500854492,
      "learning_rate": 2.6339378778403167e-05,
      "loss": 0.0911,
      "step": 2270
    },
    {
      "epoch": 1.425891181988743,
      "grad_norm": 0.2139541655778885,
      "learning_rate": 2.6235146966854284e-05,
      "loss": 0.0258,
      "step": 2280
    },
    {
      "epoch": 1.4321450906816762,
      "grad_norm": 10.919672012329102,
      "learning_rate": 2.6130915155305404e-05,
      "loss": 0.1199,
      "step": 2290
    },
    {
      "epoch": 1.4383989993746091,
      "grad_norm": 5.081328868865967,
      "learning_rate": 2.6026683343756514e-05,
      "loss": 0.1346,
      "step": 2300
    },
    {
      "epoch": 1.444652908067542,
      "grad_norm": 7.403633117675781,
      "learning_rate": 2.592245153220763e-05,
      "loss": 0.0916,
      "step": 2310
    },
    {
      "epoch": 1.4509068167604753,
      "grad_norm": 0.5151103734970093,
      "learning_rate": 2.5818219720658747e-05,
      "loss": 0.0897,
      "step": 2320
    },
    {
      "epoch": 1.4571607254534085,
      "grad_norm": 0.6174492239952087,
      "learning_rate": 2.571398790910986e-05,
      "loss": 0.0357,
      "step": 2330
    },
    {
      "epoch": 1.4634146341463414,
      "grad_norm": 0.49356457591056824,
      "learning_rate": 2.5609756097560977e-05,
      "loss": 0.0417,
      "step": 2340
    },
    {
      "epoch": 1.4696685428392746,
      "grad_norm": 0.8909059762954712,
      "learning_rate": 2.5505524286012093e-05,
      "loss": 0.0704,
      "step": 2350
    },
    {
      "epoch": 1.4759224515322076,
      "grad_norm": 1.8421276807785034,
      "learning_rate": 2.5401292474463207e-05,
      "loss": 0.1548,
      "step": 2360
    },
    {
      "epoch": 1.4821763602251408,
      "grad_norm": 10.173219680786133,
      "learning_rate": 2.5297060662914323e-05,
      "loss": 0.1454,
      "step": 2370
    },
    {
      "epoch": 1.4884302689180737,
      "grad_norm": 18.288955688476562,
      "learning_rate": 2.5192828851365436e-05,
      "loss": 0.0914,
      "step": 2380
    },
    {
      "epoch": 1.494684177611007,
      "grad_norm": 3.7138915061950684,
      "learning_rate": 2.5088597039816553e-05,
      "loss": 0.0436,
      "step": 2390
    },
    {
      "epoch": 1.50093808630394,
      "grad_norm": 0.07434119284152985,
      "learning_rate": 2.4984365228267666e-05,
      "loss": 0.0426,
      "step": 2400
    },
    {
      "epoch": 1.507191994996873,
      "grad_norm": 29.999311447143555,
      "learning_rate": 2.4880133416718783e-05,
      "loss": 0.1631,
      "step": 2410
    },
    {
      "epoch": 1.513445903689806,
      "grad_norm": 17.219730377197266,
      "learning_rate": 2.47759016051699e-05,
      "loss": 0.0322,
      "step": 2420
    },
    {
      "epoch": 1.5196998123827392,
      "grad_norm": 20.619421005249023,
      "learning_rate": 2.4671669793621013e-05,
      "loss": 0.1463,
      "step": 2430
    },
    {
      "epoch": 1.5259537210756724,
      "grad_norm": 10.154913902282715,
      "learning_rate": 2.456743798207213e-05,
      "loss": 0.0996,
      "step": 2440
    },
    {
      "epoch": 1.5322076297686054,
      "grad_norm": 0.5900272727012634,
      "learning_rate": 2.4463206170523246e-05,
      "loss": 0.0744,
      "step": 2450
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 24.516210556030273,
      "learning_rate": 2.435897435897436e-05,
      "loss": 0.1011,
      "step": 2460
    },
    {
      "epoch": 1.5447154471544715,
      "grad_norm": 1.6901098489761353,
      "learning_rate": 2.4254742547425473e-05,
      "loss": 0.0875,
      "step": 2470
    },
    {
      "epoch": 1.5509693558474047,
      "grad_norm": 14.560423851013184,
      "learning_rate": 2.4150510735876593e-05,
      "loss": 0.0872,
      "step": 2480
    },
    {
      "epoch": 1.5572232645403377,
      "grad_norm": 0.08914842456579208,
      "learning_rate": 2.4046278924327706e-05,
      "loss": 0.205,
      "step": 2490
    },
    {
      "epoch": 1.5634771732332708,
      "grad_norm": 11.586012840270996,
      "learning_rate": 2.394204711277882e-05,
      "loss": 0.0308,
      "step": 2500
    },
    {
      "epoch": 1.569731081926204,
      "grad_norm": 54.59172439575195,
      "learning_rate": 2.383781530122994e-05,
      "loss": 0.0826,
      "step": 2510
    },
    {
      "epoch": 1.575984990619137,
      "grad_norm": 0.11092808097600937,
      "learning_rate": 2.3733583489681052e-05,
      "loss": 0.1193,
      "step": 2520
    },
    {
      "epoch": 1.58223889931207,
      "grad_norm": 0.1267755925655365,
      "learning_rate": 2.3629351678132166e-05,
      "loss": 0.1211,
      "step": 2530
    },
    {
      "epoch": 1.5884928080050031,
      "grad_norm": 0.4649522304534912,
      "learning_rate": 2.3525119866583282e-05,
      "loss": 0.016,
      "step": 2540
    },
    {
      "epoch": 1.5947467166979363,
      "grad_norm": 0.05075368285179138,
      "learning_rate": 2.34208880550344e-05,
      "loss": 0.1347,
      "step": 2550
    },
    {
      "epoch": 1.6010006253908693,
      "grad_norm": 0.19798973202705383,
      "learning_rate": 2.3316656243485512e-05,
      "loss": 0.1272,
      "step": 2560
    },
    {
      "epoch": 1.6072545340838023,
      "grad_norm": 15.904496192932129,
      "learning_rate": 2.321242443193663e-05,
      "loss": 0.1195,
      "step": 2570
    },
    {
      "epoch": 1.6135084427767354,
      "grad_norm": 0.9865089058876038,
      "learning_rate": 2.3108192620387745e-05,
      "loss": 0.0658,
      "step": 2580
    },
    {
      "epoch": 1.6197623514696686,
      "grad_norm": 0.7278792858123779,
      "learning_rate": 2.300396080883886e-05,
      "loss": 0.0387,
      "step": 2590
    },
    {
      "epoch": 1.6260162601626016,
      "grad_norm": 8.343572616577148,
      "learning_rate": 2.2899728997289975e-05,
      "loss": 0.1783,
      "step": 2600
    },
    {
      "epoch": 1.6322701688555346,
      "grad_norm": 0.17786404490470886,
      "learning_rate": 2.279549718574109e-05,
      "loss": 0.1297,
      "step": 2610
    },
    {
      "epoch": 1.6385240775484677,
      "grad_norm": 0.2445105016231537,
      "learning_rate": 2.2691265374192205e-05,
      "loss": 0.1792,
      "step": 2620
    },
    {
      "epoch": 1.644777986241401,
      "grad_norm": 0.3991906940937042,
      "learning_rate": 2.258703356264332e-05,
      "loss": 0.1109,
      "step": 2630
    },
    {
      "epoch": 1.6510318949343339,
      "grad_norm": 16.85204315185547,
      "learning_rate": 2.2482801751094435e-05,
      "loss": 0.0553,
      "step": 2640
    },
    {
      "epoch": 1.657285803627267,
      "grad_norm": 0.6507587432861328,
      "learning_rate": 2.2378569939545552e-05,
      "loss": 0.0877,
      "step": 2650
    },
    {
      "epoch": 1.6635397123202003,
      "grad_norm": 0.8281304240226746,
      "learning_rate": 2.2274338127996665e-05,
      "loss": 0.021,
      "step": 2660
    },
    {
      "epoch": 1.6697936210131332,
      "grad_norm": 6.584444522857666,
      "learning_rate": 2.217010631644778e-05,
      "loss": 0.0465,
      "step": 2670
    },
    {
      "epoch": 1.6760475297060662,
      "grad_norm": 0.07537899911403656,
      "learning_rate": 2.2065874504898895e-05,
      "loss": 0.0603,
      "step": 2680
    },
    {
      "epoch": 1.6823014383989994,
      "grad_norm": 17.866968154907227,
      "learning_rate": 2.196164269335001e-05,
      "loss": 0.0468,
      "step": 2690
    },
    {
      "epoch": 1.6885553470919326,
      "grad_norm": 0.08060269802808762,
      "learning_rate": 2.1857410881801128e-05,
      "loss": 0.0891,
      "step": 2700
    },
    {
      "epoch": 1.6948092557848655,
      "grad_norm": 0.08026513457298279,
      "learning_rate": 2.175317907025224e-05,
      "loss": 0.0473,
      "step": 2710
    },
    {
      "epoch": 1.7010631644777985,
      "grad_norm": 6.778684139251709,
      "learning_rate": 2.1648947258703355e-05,
      "loss": 0.0923,
      "step": 2720
    },
    {
      "epoch": 1.7073170731707317,
      "grad_norm": 9.659918785095215,
      "learning_rate": 2.1544715447154475e-05,
      "loss": 0.0679,
      "step": 2730
    },
    {
      "epoch": 1.7135709818636649,
      "grad_norm": 25.7305965423584,
      "learning_rate": 2.1440483635605588e-05,
      "loss": 0.1035,
      "step": 2740
    },
    {
      "epoch": 1.7198248905565978,
      "grad_norm": 4.740624904632568,
      "learning_rate": 2.13362518240567e-05,
      "loss": 0.0832,
      "step": 2750
    },
    {
      "epoch": 1.726078799249531,
      "grad_norm": 0.3726472854614258,
      "learning_rate": 2.123202001250782e-05,
      "loss": 0.0847,
      "step": 2760
    },
    {
      "epoch": 1.7323327079424642,
      "grad_norm": 2.4983396530151367,
      "learning_rate": 2.1127788200958934e-05,
      "loss": 0.0535,
      "step": 2770
    },
    {
      "epoch": 1.7385866166353972,
      "grad_norm": 0.2709619104862213,
      "learning_rate": 2.1023556389410048e-05,
      "loss": 0.0428,
      "step": 2780
    },
    {
      "epoch": 1.7448405253283301,
      "grad_norm": 10.534539222717285,
      "learning_rate": 2.0919324577861164e-05,
      "loss": 0.1857,
      "step": 2790
    },
    {
      "epoch": 1.7510944340212633,
      "grad_norm": 1.5311353206634521,
      "learning_rate": 2.081509276631228e-05,
      "loss": 0.1405,
      "step": 2800
    },
    {
      "epoch": 1.7573483427141965,
      "grad_norm": 0.09128742665052414,
      "learning_rate": 2.0710860954763394e-05,
      "loss": 0.054,
      "step": 2810
    },
    {
      "epoch": 1.7636022514071295,
      "grad_norm": 0.07677879929542542,
      "learning_rate": 2.060662914321451e-05,
      "loss": 0.0921,
      "step": 2820
    },
    {
      "epoch": 1.7698561601000624,
      "grad_norm": 4.500062465667725,
      "learning_rate": 2.0502397331665627e-05,
      "loss": 0.0732,
      "step": 2830
    },
    {
      "epoch": 1.7761100687929956,
      "grad_norm": 8.949225425720215,
      "learning_rate": 2.039816552011674e-05,
      "loss": 0.0695,
      "step": 2840
    },
    {
      "epoch": 1.7823639774859288,
      "grad_norm": 0.06878305226564407,
      "learning_rate": 2.0293933708567854e-05,
      "loss": 0.1072,
      "step": 2850
    },
    {
      "epoch": 1.7886178861788617,
      "grad_norm": 0.7438960671424866,
      "learning_rate": 2.018970189701897e-05,
      "loss": 0.0538,
      "step": 2860
    },
    {
      "epoch": 1.7948717948717947,
      "grad_norm": 12.813776016235352,
      "learning_rate": 2.0085470085470087e-05,
      "loss": 0.0586,
      "step": 2870
    },
    {
      "epoch": 1.8011257035647281,
      "grad_norm": 0.03767913207411766,
      "learning_rate": 1.99812382739212e-05,
      "loss": 0.0863,
      "step": 2880
    },
    {
      "epoch": 1.807379612257661,
      "grad_norm": 0.03389982879161835,
      "learning_rate": 1.9877006462372317e-05,
      "loss": 0.0571,
      "step": 2890
    },
    {
      "epoch": 1.813633520950594,
      "grad_norm": 10.080598831176758,
      "learning_rate": 1.9772774650823434e-05,
      "loss": 0.0915,
      "step": 2900
    },
    {
      "epoch": 1.8198874296435272,
      "grad_norm": 4.838637828826904,
      "learning_rate": 1.9668542839274547e-05,
      "loss": 0.1506,
      "step": 2910
    },
    {
      "epoch": 1.8261413383364604,
      "grad_norm": 0.07617270946502686,
      "learning_rate": 1.9564311027725664e-05,
      "loss": 0.163,
      "step": 2920
    },
    {
      "epoch": 1.8323952470293934,
      "grad_norm": 2.7700746059417725,
      "learning_rate": 1.9460079216176777e-05,
      "loss": 0.0797,
      "step": 2930
    },
    {
      "epoch": 1.8386491557223263,
      "grad_norm": 0.9938766956329346,
      "learning_rate": 1.9355847404627894e-05,
      "loss": 0.1307,
      "step": 2940
    },
    {
      "epoch": 1.8449030644152595,
      "grad_norm": 0.1157880574464798,
      "learning_rate": 1.925161559307901e-05,
      "loss": 0.1168,
      "step": 2950
    },
    {
      "epoch": 1.8511569731081927,
      "grad_norm": 0.1460840106010437,
      "learning_rate": 1.9147383781530123e-05,
      "loss": 0.1461,
      "step": 2960
    },
    {
      "epoch": 1.8574108818011257,
      "grad_norm": 0.1620333045721054,
      "learning_rate": 1.904315196998124e-05,
      "loss": 0.0766,
      "step": 2970
    },
    {
      "epoch": 1.8636647904940586,
      "grad_norm": 0.08686767518520355,
      "learning_rate": 1.8938920158432357e-05,
      "loss": 0.0915,
      "step": 2980
    },
    {
      "epoch": 1.8699186991869918,
      "grad_norm": 0.229703888297081,
      "learning_rate": 1.883468834688347e-05,
      "loss": 0.098,
      "step": 2990
    },
    {
      "epoch": 1.876172607879925,
      "grad_norm": 0.8074817657470703,
      "learning_rate": 1.8730456535334583e-05,
      "loss": 0.1335,
      "step": 3000
    },
    {
      "epoch": 1.882426516572858,
      "grad_norm": 0.2722013294696808,
      "learning_rate": 1.86262247237857e-05,
      "loss": 0.046,
      "step": 3010
    },
    {
      "epoch": 1.8886804252657912,
      "grad_norm": 8.586812973022461,
      "learning_rate": 1.8521992912236816e-05,
      "loss": 0.1232,
      "step": 3020
    },
    {
      "epoch": 1.8949343339587243,
      "grad_norm": 0.06670204550027847,
      "learning_rate": 1.841776110068793e-05,
      "loss": 0.0528,
      "step": 3030
    },
    {
      "epoch": 1.9011882426516573,
      "grad_norm": 0.16074185073375702,
      "learning_rate": 1.8313529289139046e-05,
      "loss": 0.0159,
      "step": 3040
    },
    {
      "epoch": 1.9074421513445903,
      "grad_norm": 0.150889590382576,
      "learning_rate": 1.8209297477590163e-05,
      "loss": 0.068,
      "step": 3050
    },
    {
      "epoch": 1.9136960600375235,
      "grad_norm": 6.567229270935059,
      "learning_rate": 1.8105065666041276e-05,
      "loss": 0.1712,
      "step": 3060
    },
    {
      "epoch": 1.9199499687304566,
      "grad_norm": 0.18101075291633606,
      "learning_rate": 1.800083385449239e-05,
      "loss": 0.1235,
      "step": 3070
    },
    {
      "epoch": 1.9262038774233896,
      "grad_norm": 0.4023401439189911,
      "learning_rate": 1.789660204294351e-05,
      "loss": 0.0974,
      "step": 3080
    },
    {
      "epoch": 1.9324577861163226,
      "grad_norm": 4.3390092849731445,
      "learning_rate": 1.7792370231394623e-05,
      "loss": 0.0334,
      "step": 3090
    },
    {
      "epoch": 1.9387116948092558,
      "grad_norm": 0.2189558893442154,
      "learning_rate": 1.7688138419845736e-05,
      "loss": 0.0159,
      "step": 3100
    },
    {
      "epoch": 1.944965603502189,
      "grad_norm": 0.18300659954547882,
      "learning_rate": 1.7583906608296853e-05,
      "loss": 0.08,
      "step": 3110
    },
    {
      "epoch": 1.951219512195122,
      "grad_norm": 10.743593215942383,
      "learning_rate": 1.747967479674797e-05,
      "loss": 0.1069,
      "step": 3120
    },
    {
      "epoch": 1.9574734208880549,
      "grad_norm": 2.026268482208252,
      "learning_rate": 1.7375442985199082e-05,
      "loss": 0.1486,
      "step": 3130
    },
    {
      "epoch": 1.9637273295809883,
      "grad_norm": 0.0737457275390625,
      "learning_rate": 1.72712111736502e-05,
      "loss": 0.0944,
      "step": 3140
    },
    {
      "epoch": 1.9699812382739212,
      "grad_norm": 11.659198760986328,
      "learning_rate": 1.7166979362101316e-05,
      "loss": 0.0488,
      "step": 3150
    },
    {
      "epoch": 1.9762351469668542,
      "grad_norm": 0.12197858095169067,
      "learning_rate": 1.706274755055243e-05,
      "loss": 0.0459,
      "step": 3160
    },
    {
      "epoch": 1.9824890556597874,
      "grad_norm": 15.860309600830078,
      "learning_rate": 1.6958515739003546e-05,
      "loss": 0.1157,
      "step": 3170
    },
    {
      "epoch": 1.9887429643527206,
      "grad_norm": 2.1709988117218018,
      "learning_rate": 1.685428392745466e-05,
      "loss": 0.0974,
      "step": 3180
    },
    {
      "epoch": 1.9949968730456535,
      "grad_norm": 0.0550648458302021,
      "learning_rate": 1.6750052115905776e-05,
      "loss": 0.0569,
      "step": 3190
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9596433599249179,
      "eval_loss": 0.15561935305595398,
      "eval_runtime": 9.6202,
      "eval_samples_per_second": 664.54,
      "eval_steps_per_second": 41.579,
      "step": 3198
    }
  ],
  "logging_steps": 10,
  "max_steps": 4797,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 16242541562880.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
