{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1599,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006253908692933083,
      "grad_norm": 4.291099548339844,
      "learning_rate": 4.989576818845112e-05,
      "loss": 0.0747,
      "step": 10
    },
    {
      "epoch": 0.012507817385866166,
      "grad_norm": 0.2860782742500305,
      "learning_rate": 4.979153637690223e-05,
      "loss": 0.2587,
      "step": 20
    },
    {
      "epoch": 0.01876172607879925,
      "grad_norm": 0.6768456101417542,
      "learning_rate": 4.9687304565353346e-05,
      "loss": 0.0483,
      "step": 30
    },
    {
      "epoch": 0.025015634771732333,
      "grad_norm": 5.607723712921143,
      "learning_rate": 4.958307275380447e-05,
      "loss": 0.0903,
      "step": 40
    },
    {
      "epoch": 0.031269543464665414,
      "grad_norm": 19.320632934570312,
      "learning_rate": 4.947884094225558e-05,
      "loss": 0.179,
      "step": 50
    },
    {
      "epoch": 0.0375234521575985,
      "grad_norm": 0.769263744354248,
      "learning_rate": 4.9374609130706695e-05,
      "loss": 0.1134,
      "step": 60
    },
    {
      "epoch": 0.043777360850531584,
      "grad_norm": 7.984750270843506,
      "learning_rate": 4.9270377319157805e-05,
      "loss": 0.1266,
      "step": 70
    },
    {
      "epoch": 0.050031269543464665,
      "grad_norm": 0.18168975412845612,
      "learning_rate": 4.916614550760892e-05,
      "loss": 0.083,
      "step": 80
    },
    {
      "epoch": 0.05628517823639775,
      "grad_norm": 3.23276686668396,
      "learning_rate": 4.906191369606004e-05,
      "loss": 0.0512,
      "step": 90
    },
    {
      "epoch": 0.06253908692933083,
      "grad_norm": 9.676409721374512,
      "learning_rate": 4.8957681884511155e-05,
      "loss": 0.0884,
      "step": 100
    },
    {
      "epoch": 0.06879299562226392,
      "grad_norm": 0.3160267174243927,
      "learning_rate": 4.885345007296227e-05,
      "loss": 0.0527,
      "step": 110
    },
    {
      "epoch": 0.075046904315197,
      "grad_norm": 4.140906810760498,
      "learning_rate": 4.874921826141339e-05,
      "loss": 0.0502,
      "step": 120
    },
    {
      "epoch": 0.08130081300813008,
      "grad_norm": 0.10053111612796783,
      "learning_rate": 4.86449864498645e-05,
      "loss": 0.0415,
      "step": 130
    },
    {
      "epoch": 0.08755472170106317,
      "grad_norm": 0.6729695796966553,
      "learning_rate": 4.8540754638315615e-05,
      "loss": 0.0658,
      "step": 140
    },
    {
      "epoch": 0.09380863039399624,
      "grad_norm": 0.06278358399868011,
      "learning_rate": 4.843652282676673e-05,
      "loss": 0.0435,
      "step": 150
    },
    {
      "epoch": 0.10006253908692933,
      "grad_norm": 0.6027106642723083,
      "learning_rate": 4.833229101521785e-05,
      "loss": 0.1804,
      "step": 160
    },
    {
      "epoch": 0.10631644777986242,
      "grad_norm": 1.0174719095230103,
      "learning_rate": 4.8228059203668965e-05,
      "loss": 0.1179,
      "step": 170
    },
    {
      "epoch": 0.1125703564727955,
      "grad_norm": 0.07532531768083572,
      "learning_rate": 4.812382739212008e-05,
      "loss": 0.0447,
      "step": 180
    },
    {
      "epoch": 0.11882426516572858,
      "grad_norm": 0.23015403747558594,
      "learning_rate": 4.801959558057119e-05,
      "loss": 0.1205,
      "step": 190
    },
    {
      "epoch": 0.12507817385866166,
      "grad_norm": 3.0194406509399414,
      "learning_rate": 4.791536376902231e-05,
      "loss": 0.0479,
      "step": 200
    },
    {
      "epoch": 0.13133208255159476,
      "grad_norm": 1.0671087503433228,
      "learning_rate": 4.781113195747342e-05,
      "loss": 0.0318,
      "step": 210
    },
    {
      "epoch": 0.13758599124452783,
      "grad_norm": 0.08635252714157104,
      "learning_rate": 4.770690014592454e-05,
      "loss": 0.1041,
      "step": 220
    },
    {
      "epoch": 0.1438398999374609,
      "grad_norm": 0.10599970817565918,
      "learning_rate": 4.760266833437566e-05,
      "loss": 0.0619,
      "step": 230
    },
    {
      "epoch": 0.150093808630394,
      "grad_norm": 6.836989402770996,
      "learning_rate": 4.749843652282677e-05,
      "loss": 0.1333,
      "step": 240
    },
    {
      "epoch": 0.15634771732332708,
      "grad_norm": 0.9700784087181091,
      "learning_rate": 4.7394204711277884e-05,
      "loss": 0.0907,
      "step": 250
    },
    {
      "epoch": 0.16260162601626016,
      "grad_norm": 0.1064070612192154,
      "learning_rate": 4.7289972899729e-05,
      "loss": 0.0971,
      "step": 260
    },
    {
      "epoch": 0.16885553470919323,
      "grad_norm": 11.843490600585938,
      "learning_rate": 4.718574108818011e-05,
      "loss": 0.0984,
      "step": 270
    },
    {
      "epoch": 0.17510944340212634,
      "grad_norm": 0.44960957765579224,
      "learning_rate": 4.708150927663123e-05,
      "loss": 0.0479,
      "step": 280
    },
    {
      "epoch": 0.1813633520950594,
      "grad_norm": 0.7914291024208069,
      "learning_rate": 4.697727746508235e-05,
      "loss": 0.0547,
      "step": 290
    },
    {
      "epoch": 0.18761726078799248,
      "grad_norm": 0.12643112242221832,
      "learning_rate": 4.687304565353346e-05,
      "loss": 0.0802,
      "step": 300
    },
    {
      "epoch": 0.1938711694809256,
      "grad_norm": 0.2583915889263153,
      "learning_rate": 4.676881384198458e-05,
      "loss": 0.1113,
      "step": 310
    },
    {
      "epoch": 0.20012507817385866,
      "grad_norm": 17.662296295166016,
      "learning_rate": 4.666458203043569e-05,
      "loss": 0.0262,
      "step": 320
    },
    {
      "epoch": 0.20637898686679174,
      "grad_norm": 7.00095796585083,
      "learning_rate": 4.6560350218886804e-05,
      "loss": 0.1184,
      "step": 330
    },
    {
      "epoch": 0.21263289555972484,
      "grad_norm": 0.14874887466430664,
      "learning_rate": 4.645611840733792e-05,
      "loss": 0.1073,
      "step": 340
    },
    {
      "epoch": 0.2188868042526579,
      "grad_norm": 6.306918144226074,
      "learning_rate": 4.635188659578904e-05,
      "loss": 0.0287,
      "step": 350
    },
    {
      "epoch": 0.225140712945591,
      "grad_norm": 0.20109951496124268,
      "learning_rate": 4.6247654784240154e-05,
      "loss": 0.0698,
      "step": 360
    },
    {
      "epoch": 0.2313946216385241,
      "grad_norm": 0.09608227014541626,
      "learning_rate": 4.614342297269127e-05,
      "loss": 0.0486,
      "step": 370
    },
    {
      "epoch": 0.23764853033145716,
      "grad_norm": 15.688694953918457,
      "learning_rate": 4.603919116114238e-05,
      "loss": 0.1249,
      "step": 380
    },
    {
      "epoch": 0.24390243902439024,
      "grad_norm": 9.634652137756348,
      "learning_rate": 4.59349593495935e-05,
      "loss": 0.0956,
      "step": 390
    },
    {
      "epoch": 0.2501563477173233,
      "grad_norm": 7.74387788772583,
      "learning_rate": 4.5830727538044614e-05,
      "loss": 0.111,
      "step": 400
    },
    {
      "epoch": 0.2564102564102564,
      "grad_norm": 13.138375282287598,
      "learning_rate": 4.572649572649573e-05,
      "loss": 0.1092,
      "step": 410
    },
    {
      "epoch": 0.2626641651031895,
      "grad_norm": 5.915304183959961,
      "learning_rate": 4.562226391494685e-05,
      "loss": 0.0953,
      "step": 420
    },
    {
      "epoch": 0.2689180737961226,
      "grad_norm": 6.373575210571289,
      "learning_rate": 4.5518032103397964e-05,
      "loss": 0.0574,
      "step": 430
    },
    {
      "epoch": 0.27517198248905567,
      "grad_norm": 6.757223606109619,
      "learning_rate": 4.541380029184907e-05,
      "loss": 0.0815,
      "step": 440
    },
    {
      "epoch": 0.28142589118198874,
      "grad_norm": 0.21939584612846375,
      "learning_rate": 4.530956848030019e-05,
      "loss": 0.0448,
      "step": 450
    },
    {
      "epoch": 0.2876797998749218,
      "grad_norm": 13.826632499694824,
      "learning_rate": 4.52053366687513e-05,
      "loss": 0.0575,
      "step": 460
    },
    {
      "epoch": 0.2939337085678549,
      "grad_norm": 10.636237144470215,
      "learning_rate": 4.5101104857202417e-05,
      "loss": 0.0768,
      "step": 470
    },
    {
      "epoch": 0.300187617260788,
      "grad_norm": 2.1250033378601074,
      "learning_rate": 4.499687304565354e-05,
      "loss": 0.1001,
      "step": 480
    },
    {
      "epoch": 0.3064415259537211,
      "grad_norm": 8.72056770324707,
      "learning_rate": 4.489264123410465e-05,
      "loss": 0.1731,
      "step": 490
    },
    {
      "epoch": 0.31269543464665417,
      "grad_norm": 7.16171932220459,
      "learning_rate": 4.4788409422555766e-05,
      "loss": 0.0986,
      "step": 500
    },
    {
      "epoch": 0.31894934333958724,
      "grad_norm": 0.383806049823761,
      "learning_rate": 4.468417761100688e-05,
      "loss": 0.0403,
      "step": 510
    },
    {
      "epoch": 0.3252032520325203,
      "grad_norm": 0.0500686839222908,
      "learning_rate": 4.457994579945799e-05,
      "loss": 0.062,
      "step": 520
    },
    {
      "epoch": 0.3314571607254534,
      "grad_norm": 9.560412406921387,
      "learning_rate": 4.447571398790911e-05,
      "loss": 0.1072,
      "step": 530
    },
    {
      "epoch": 0.33771106941838647,
      "grad_norm": 1.650088906288147,
      "learning_rate": 4.4371482176360226e-05,
      "loss": 0.1248,
      "step": 540
    },
    {
      "epoch": 0.3439649781113196,
      "grad_norm": 0.08336286246776581,
      "learning_rate": 4.426725036481134e-05,
      "loss": 0.0623,
      "step": 550
    },
    {
      "epoch": 0.35021888680425267,
      "grad_norm": 0.07596894353628159,
      "learning_rate": 4.416301855326246e-05,
      "loss": 0.0926,
      "step": 560
    },
    {
      "epoch": 0.35647279549718575,
      "grad_norm": 0.1307000368833542,
      "learning_rate": 4.4058786741713576e-05,
      "loss": 0.0637,
      "step": 570
    },
    {
      "epoch": 0.3627267041901188,
      "grad_norm": 0.733466386795044,
      "learning_rate": 4.3954554930164686e-05,
      "loss": 0.0177,
      "step": 580
    },
    {
      "epoch": 0.3689806128830519,
      "grad_norm": 0.17071810364723206,
      "learning_rate": 4.38503231186158e-05,
      "loss": 0.0699,
      "step": 590
    },
    {
      "epoch": 0.37523452157598497,
      "grad_norm": 5.092574596405029,
      "learning_rate": 4.374609130706692e-05,
      "loss": 0.0155,
      "step": 600
    },
    {
      "epoch": 0.3814884302689181,
      "grad_norm": 0.08063679188489914,
      "learning_rate": 4.3641859495518036e-05,
      "loss": 0.0213,
      "step": 610
    },
    {
      "epoch": 0.3877423389618512,
      "grad_norm": 0.08075270801782608,
      "learning_rate": 4.353762768396915e-05,
      "loss": 0.0526,
      "step": 620
    },
    {
      "epoch": 0.39399624765478425,
      "grad_norm": 1.1400920152664185,
      "learning_rate": 4.343339587242026e-05,
      "loss": 0.1074,
      "step": 630
    },
    {
      "epoch": 0.4002501563477173,
      "grad_norm": 5.785594463348389,
      "learning_rate": 4.332916406087138e-05,
      "loss": 0.0961,
      "step": 640
    },
    {
      "epoch": 0.4065040650406504,
      "grad_norm": 10.610084533691406,
      "learning_rate": 4.3224932249322496e-05,
      "loss": 0.1521,
      "step": 650
    },
    {
      "epoch": 0.41275797373358347,
      "grad_norm": 2.0674214363098145,
      "learning_rate": 4.312070043777361e-05,
      "loss": 0.039,
      "step": 660
    },
    {
      "epoch": 0.41901188242651655,
      "grad_norm": 0.42433595657348633,
      "learning_rate": 4.301646862622473e-05,
      "loss": 0.0563,
      "step": 670
    },
    {
      "epoch": 0.4252657911194497,
      "grad_norm": 0.4235002100467682,
      "learning_rate": 4.2912236814675846e-05,
      "loss": 0.1504,
      "step": 680
    },
    {
      "epoch": 0.43151969981238275,
      "grad_norm": 0.1293834149837494,
      "learning_rate": 4.2808005003126955e-05,
      "loss": 0.0292,
      "step": 690
    },
    {
      "epoch": 0.4377736085053158,
      "grad_norm": 12.587324142456055,
      "learning_rate": 4.270377319157807e-05,
      "loss": 0.0792,
      "step": 700
    },
    {
      "epoch": 0.4440275171982489,
      "grad_norm": 0.18624401092529297,
      "learning_rate": 4.259954138002918e-05,
      "loss": 0.0872,
      "step": 710
    },
    {
      "epoch": 0.450281425891182,
      "grad_norm": 1.7729555368423462,
      "learning_rate": 4.24953095684803e-05,
      "loss": 0.0108,
      "step": 720
    },
    {
      "epoch": 0.45653533458411505,
      "grad_norm": 0.0633101537823677,
      "learning_rate": 4.239107775693142e-05,
      "loss": 0.0961,
      "step": 730
    },
    {
      "epoch": 0.4627892432770482,
      "grad_norm": 0.6789349913597107,
      "learning_rate": 4.228684594538253e-05,
      "loss": 0.0329,
      "step": 740
    },
    {
      "epoch": 0.46904315196998125,
      "grad_norm": 0.7463671565055847,
      "learning_rate": 4.218261413383365e-05,
      "loss": 0.0249,
      "step": 750
    },
    {
      "epoch": 0.47529706066291433,
      "grad_norm": 2.6279168128967285,
      "learning_rate": 4.2078382322284765e-05,
      "loss": 0.0044,
      "step": 760
    },
    {
      "epoch": 0.4815509693558474,
      "grad_norm": 0.03604523092508316,
      "learning_rate": 4.1974150510735875e-05,
      "loss": 0.0782,
      "step": 770
    },
    {
      "epoch": 0.4878048780487805,
      "grad_norm": 0.036616433411836624,
      "learning_rate": 4.186991869918699e-05,
      "loss": 0.1576,
      "step": 780
    },
    {
      "epoch": 0.49405878674171355,
      "grad_norm": 0.09100951999425888,
      "learning_rate": 4.176568688763811e-05,
      "loss": 0.0281,
      "step": 790
    },
    {
      "epoch": 0.5003126954346466,
      "grad_norm": 0.057935066521167755,
      "learning_rate": 4.1661455076089225e-05,
      "loss": 0.0658,
      "step": 800
    },
    {
      "epoch": 0.5065666041275797,
      "grad_norm": 8.132308959960938,
      "learning_rate": 4.155722326454034e-05,
      "loss": 0.0739,
      "step": 810
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 0.1469096690416336,
      "learning_rate": 4.145299145299146e-05,
      "loss": 0.1112,
      "step": 820
    },
    {
      "epoch": 0.5190744215134458,
      "grad_norm": 6.589786529541016,
      "learning_rate": 4.134875964144257e-05,
      "loss": 0.0727,
      "step": 830
    },
    {
      "epoch": 0.525328330206379,
      "grad_norm": 1.3200281858444214,
      "learning_rate": 4.1244527829893685e-05,
      "loss": 0.0436,
      "step": 840
    },
    {
      "epoch": 0.5315822388993121,
      "grad_norm": 28.305082321166992,
      "learning_rate": 4.11402960183448e-05,
      "loss": 0.0842,
      "step": 850
    },
    {
      "epoch": 0.5378361475922452,
      "grad_norm": 0.06538552790880203,
      "learning_rate": 4.103606420679592e-05,
      "loss": 0.092,
      "step": 860
    },
    {
      "epoch": 0.5440900562851783,
      "grad_norm": 0.14088158309459686,
      "learning_rate": 4.0931832395247035e-05,
      "loss": 0.0598,
      "step": 870
    },
    {
      "epoch": 0.5503439649781113,
      "grad_norm": 0.06562728434801102,
      "learning_rate": 4.0827600583698144e-05,
      "loss": 0.1129,
      "step": 880
    },
    {
      "epoch": 0.5565978736710444,
      "grad_norm": 1.05733323097229,
      "learning_rate": 4.072336877214926e-05,
      "loss": 0.0669,
      "step": 890
    },
    {
      "epoch": 0.5628517823639775,
      "grad_norm": 17.93256378173828,
      "learning_rate": 4.061913696060038e-05,
      "loss": 0.0912,
      "step": 900
    },
    {
      "epoch": 0.5691056910569106,
      "grad_norm": 9.491959571838379,
      "learning_rate": 4.051490514905149e-05,
      "loss": 0.0403,
      "step": 910
    },
    {
      "epoch": 0.5753595997498436,
      "grad_norm": 0.04010415077209473,
      "learning_rate": 4.041067333750261e-05,
      "loss": 0.1284,
      "step": 920
    },
    {
      "epoch": 0.5816135084427767,
      "grad_norm": 0.06082770228385925,
      "learning_rate": 4.030644152595373e-05,
      "loss": 0.164,
      "step": 930
    },
    {
      "epoch": 0.5878674171357098,
      "grad_norm": 0.09021168947219849,
      "learning_rate": 4.020220971440484e-05,
      "loss": 0.0896,
      "step": 940
    },
    {
      "epoch": 0.5941213258286429,
      "grad_norm": 1.4429004192352295,
      "learning_rate": 4.0097977902855954e-05,
      "loss": 0.0791,
      "step": 950
    },
    {
      "epoch": 0.600375234521576,
      "grad_norm": 2.4441921710968018,
      "learning_rate": 3.9993746091307064e-05,
      "loss": 0.049,
      "step": 960
    },
    {
      "epoch": 0.6066291432145091,
      "grad_norm": 15.107951164245605,
      "learning_rate": 3.988951427975818e-05,
      "loss": 0.1308,
      "step": 970
    },
    {
      "epoch": 0.6128830519074422,
      "grad_norm": 7.791202068328857,
      "learning_rate": 3.9785282468209304e-05,
      "loss": 0.0437,
      "step": 980
    },
    {
      "epoch": 0.6191369606003753,
      "grad_norm": 3.442681074142456,
      "learning_rate": 3.9681050656660414e-05,
      "loss": 0.0486,
      "step": 990
    },
    {
      "epoch": 0.6253908692933083,
      "grad_norm": 4.004490375518799,
      "learning_rate": 3.957681884511153e-05,
      "loss": 0.0297,
      "step": 1000
    },
    {
      "epoch": 0.6316447779862414,
      "grad_norm": 0.11028594523668289,
      "learning_rate": 3.947258703356265e-05,
      "loss": 0.0108,
      "step": 1010
    },
    {
      "epoch": 0.6378986866791745,
      "grad_norm": 0.06608215719461441,
      "learning_rate": 3.936835522201376e-05,
      "loss": 0.0531,
      "step": 1020
    },
    {
      "epoch": 0.6441525953721076,
      "grad_norm": 0.042441170662641525,
      "learning_rate": 3.9264123410464874e-05,
      "loss": 0.1287,
      "step": 1030
    },
    {
      "epoch": 0.6504065040650406,
      "grad_norm": 0.04160606116056442,
      "learning_rate": 3.915989159891599e-05,
      "loss": 0.0392,
      "step": 1040
    },
    {
      "epoch": 0.6566604127579737,
      "grad_norm": 0.11635306477546692,
      "learning_rate": 3.905565978736711e-05,
      "loss": 0.1194,
      "step": 1050
    },
    {
      "epoch": 0.6629143214509068,
      "grad_norm": 0.27154430747032166,
      "learning_rate": 3.8951427975818223e-05,
      "loss": 0.0414,
      "step": 1060
    },
    {
      "epoch": 0.6691682301438399,
      "grad_norm": 0.038260530680418015,
      "learning_rate": 3.884719616426934e-05,
      "loss": 0.0441,
      "step": 1070
    },
    {
      "epoch": 0.6754221388367729,
      "grad_norm": 0.08210691809654236,
      "learning_rate": 3.874296435272045e-05,
      "loss": 0.043,
      "step": 1080
    },
    {
      "epoch": 0.6816760475297061,
      "grad_norm": 0.04930547624826431,
      "learning_rate": 3.863873254117157e-05,
      "loss": 0.1496,
      "step": 1090
    },
    {
      "epoch": 0.6879299562226392,
      "grad_norm": 27.380029678344727,
      "learning_rate": 3.853450072962268e-05,
      "loss": 0.1203,
      "step": 1100
    },
    {
      "epoch": 0.6941838649155723,
      "grad_norm": 0.049737993627786636,
      "learning_rate": 3.84302689180738e-05,
      "loss": 0.0439,
      "step": 1110
    },
    {
      "epoch": 0.7004377736085053,
      "grad_norm": 0.6220563650131226,
      "learning_rate": 3.8326037106524917e-05,
      "loss": 0.0214,
      "step": 1120
    },
    {
      "epoch": 0.7066916823014384,
      "grad_norm": 0.05965579301118851,
      "learning_rate": 3.8221805294976026e-05,
      "loss": 0.0235,
      "step": 1130
    },
    {
      "epoch": 0.7129455909943715,
      "grad_norm": 0.06679427623748779,
      "learning_rate": 3.811757348342714e-05,
      "loss": 0.0392,
      "step": 1140
    },
    {
      "epoch": 0.7191994996873046,
      "grad_norm": 1.7009018659591675,
      "learning_rate": 3.801334167187826e-05,
      "loss": 0.0392,
      "step": 1150
    },
    {
      "epoch": 0.7254534083802376,
      "grad_norm": 0.6108495593070984,
      "learning_rate": 3.790910986032937e-05,
      "loss": 0.1139,
      "step": 1160
    },
    {
      "epoch": 0.7317073170731707,
      "grad_norm": 0.031215891242027283,
      "learning_rate": 3.780487804878049e-05,
      "loss": 0.1591,
      "step": 1170
    },
    {
      "epoch": 0.7379612257661038,
      "grad_norm": 0.11882312595844269,
      "learning_rate": 3.770064623723161e-05,
      "loss": 0.0524,
      "step": 1180
    },
    {
      "epoch": 0.7442151344590369,
      "grad_norm": 0.036917008459568024,
      "learning_rate": 3.759641442568272e-05,
      "loss": 0.0535,
      "step": 1190
    },
    {
      "epoch": 0.7504690431519699,
      "grad_norm": 3.584357738494873,
      "learning_rate": 3.7492182614133836e-05,
      "loss": 0.0279,
      "step": 1200
    },
    {
      "epoch": 0.756722951844903,
      "grad_norm": 0.03357454016804695,
      "learning_rate": 3.738795080258495e-05,
      "loss": 0.0858,
      "step": 1210
    },
    {
      "epoch": 0.7629768605378362,
      "grad_norm": 10.675154685974121,
      "learning_rate": 3.728371899103606e-05,
      "loss": 0.027,
      "step": 1220
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 0.04237139970064163,
      "learning_rate": 3.717948717948718e-05,
      "loss": 0.0386,
      "step": 1230
    },
    {
      "epoch": 0.7754846779237023,
      "grad_norm": 0.10772591829299927,
      "learning_rate": 3.7075255367938296e-05,
      "loss": 0.0495,
      "step": 1240
    },
    {
      "epoch": 0.7817385866166354,
      "grad_norm": 11.118101119995117,
      "learning_rate": 3.697102355638941e-05,
      "loss": 0.0424,
      "step": 1250
    },
    {
      "epoch": 0.7879924953095685,
      "grad_norm": 0.10572243481874466,
      "learning_rate": 3.686679174484053e-05,
      "loss": 0.0649,
      "step": 1260
    },
    {
      "epoch": 0.7942464040025016,
      "grad_norm": 0.027645647525787354,
      "learning_rate": 3.676255993329164e-05,
      "loss": 0.0422,
      "step": 1270
    },
    {
      "epoch": 0.8005003126954346,
      "grad_norm": 7.8873701095581055,
      "learning_rate": 3.6658328121742756e-05,
      "loss": 0.0951,
      "step": 1280
    },
    {
      "epoch": 0.8067542213883677,
      "grad_norm": 0.042448740452528,
      "learning_rate": 3.655409631019387e-05,
      "loss": 0.034,
      "step": 1290
    },
    {
      "epoch": 0.8130081300813008,
      "grad_norm": 0.08420506864786148,
      "learning_rate": 3.644986449864499e-05,
      "loss": 0.0791,
      "step": 1300
    },
    {
      "epoch": 0.8192620387742339,
      "grad_norm": 0.03296882286667824,
      "learning_rate": 3.6345632687096105e-05,
      "loss": 0.117,
      "step": 1310
    },
    {
      "epoch": 0.8255159474671669,
      "grad_norm": 3.50466251373291,
      "learning_rate": 3.624140087554722e-05,
      "loss": 0.0587,
      "step": 1320
    },
    {
      "epoch": 0.8317698561601,
      "grad_norm": 11.576956748962402,
      "learning_rate": 3.613716906399833e-05,
      "loss": 0.0512,
      "step": 1330
    },
    {
      "epoch": 0.8380237648530331,
      "grad_norm": 0.04870525747537613,
      "learning_rate": 3.603293725244945e-05,
      "loss": 0.1568,
      "step": 1340
    },
    {
      "epoch": 0.8442776735459663,
      "grad_norm": 3.14689040184021,
      "learning_rate": 3.5928705440900565e-05,
      "loss": 0.1214,
      "step": 1350
    },
    {
      "epoch": 0.8505315822388994,
      "grad_norm": 17.910242080688477,
      "learning_rate": 3.582447362935168e-05,
      "loss": 0.1309,
      "step": 1360
    },
    {
      "epoch": 0.8567854909318324,
      "grad_norm": 12.026419639587402,
      "learning_rate": 3.57202418178028e-05,
      "loss": 0.0563,
      "step": 1370
    },
    {
      "epoch": 0.8630393996247655,
      "grad_norm": 0.07085279375314713,
      "learning_rate": 3.561601000625391e-05,
      "loss": 0.0408,
      "step": 1380
    },
    {
      "epoch": 0.8692933083176986,
      "grad_norm": 1.008329153060913,
      "learning_rate": 3.5511778194705025e-05,
      "loss": 0.079,
      "step": 1390
    },
    {
      "epoch": 0.8755472170106317,
      "grad_norm": 10.595829010009766,
      "learning_rate": 3.540754638315614e-05,
      "loss": 0.0969,
      "step": 1400
    },
    {
      "epoch": 0.8818011257035647,
      "grad_norm": 19.474098205566406,
      "learning_rate": 3.530331457160725e-05,
      "loss": 0.0129,
      "step": 1410
    },
    {
      "epoch": 0.8880550343964978,
      "grad_norm": 6.5079345703125,
      "learning_rate": 3.5199082760058375e-05,
      "loss": 0.0937,
      "step": 1420
    },
    {
      "epoch": 0.8943089430894309,
      "grad_norm": 0.10278644412755966,
      "learning_rate": 3.509485094850949e-05,
      "loss": 0.0609,
      "step": 1430
    },
    {
      "epoch": 0.900562851782364,
      "grad_norm": 0.3874758780002594,
      "learning_rate": 3.49906191369606e-05,
      "loss": 0.0434,
      "step": 1440
    },
    {
      "epoch": 0.906816760475297,
      "grad_norm": 5.10392427444458,
      "learning_rate": 3.488638732541172e-05,
      "loss": 0.0733,
      "step": 1450
    },
    {
      "epoch": 0.9130706691682301,
      "grad_norm": 0.3235251009464264,
      "learning_rate": 3.4782155513862835e-05,
      "loss": 0.1076,
      "step": 1460
    },
    {
      "epoch": 0.9193245778611632,
      "grad_norm": 0.0452614426612854,
      "learning_rate": 3.4677923702313945e-05,
      "loss": 0.0793,
      "step": 1470
    },
    {
      "epoch": 0.9255784865540964,
      "grad_norm": 12.353853225708008,
      "learning_rate": 3.457369189076506e-05,
      "loss": 0.1126,
      "step": 1480
    },
    {
      "epoch": 0.9318323952470294,
      "grad_norm": 0.21806354820728302,
      "learning_rate": 3.446946007921618e-05,
      "loss": 0.2261,
      "step": 1490
    },
    {
      "epoch": 0.9380863039399625,
      "grad_norm": 0.08168236911296844,
      "learning_rate": 3.4365228267667294e-05,
      "loss": 0.0961,
      "step": 1500
    },
    {
      "epoch": 0.9443402126328956,
      "grad_norm": 0.2565726637840271,
      "learning_rate": 3.426099645611841e-05,
      "loss": 0.0525,
      "step": 1510
    },
    {
      "epoch": 0.9505941213258287,
      "grad_norm": 9.767847061157227,
      "learning_rate": 3.415676464456952e-05,
      "loss": 0.0738,
      "step": 1520
    },
    {
      "epoch": 0.9568480300187617,
      "grad_norm": 5.232820987701416,
      "learning_rate": 3.405253283302064e-05,
      "loss": 0.0772,
      "step": 1530
    },
    {
      "epoch": 0.9631019387116948,
      "grad_norm": 1.5355411767959595,
      "learning_rate": 3.3948301021471754e-05,
      "loss": 0.0607,
      "step": 1540
    },
    {
      "epoch": 0.9693558474046279,
      "grad_norm": 2.879824161529541,
      "learning_rate": 3.384406920992287e-05,
      "loss": 0.0422,
      "step": 1550
    },
    {
      "epoch": 0.975609756097561,
      "grad_norm": 0.21715925633907318,
      "learning_rate": 3.373983739837399e-05,
      "loss": 0.0562,
      "step": 1560
    },
    {
      "epoch": 0.981863664790494,
      "grad_norm": 14.328224182128906,
      "learning_rate": 3.3635605586825104e-05,
      "loss": 0.1179,
      "step": 1570
    },
    {
      "epoch": 0.9881175734834271,
      "grad_norm": 0.6427140831947327,
      "learning_rate": 3.3531373775276214e-05,
      "loss": 0.0759,
      "step": 1580
    },
    {
      "epoch": 0.9943714821763602,
      "grad_norm": 0.0810517817735672,
      "learning_rate": 3.342714196372733e-05,
      "loss": 0.0688,
      "step": 1590
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9576098858126075,
      "eval_loss": 0.16604188084602356,
      "eval_runtime": 9.6112,
      "eval_samples_per_second": 665.163,
      "eval_steps_per_second": 41.618,
      "step": 1599
    }
  ],
  "logging_steps": 10,
  "max_steps": 4797,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8121270781440.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
