{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 4797,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006253908692933083,
      "grad_norm": 4.291099548339844,
      "learning_rate": 4.989576818845112e-05,
      "loss": 0.0747,
      "step": 10
    },
    {
      "epoch": 0.012507817385866166,
      "grad_norm": 0.2860782742500305,
      "learning_rate": 4.979153637690223e-05,
      "loss": 0.2587,
      "step": 20
    },
    {
      "epoch": 0.01876172607879925,
      "grad_norm": 0.6768456101417542,
      "learning_rate": 4.9687304565353346e-05,
      "loss": 0.0483,
      "step": 30
    },
    {
      "epoch": 0.025015634771732333,
      "grad_norm": 5.607723712921143,
      "learning_rate": 4.958307275380447e-05,
      "loss": 0.0903,
      "step": 40
    },
    {
      "epoch": 0.031269543464665414,
      "grad_norm": 19.320632934570312,
      "learning_rate": 4.947884094225558e-05,
      "loss": 0.179,
      "step": 50
    },
    {
      "epoch": 0.0375234521575985,
      "grad_norm": 0.769263744354248,
      "learning_rate": 4.9374609130706695e-05,
      "loss": 0.1134,
      "step": 60
    },
    {
      "epoch": 0.043777360850531584,
      "grad_norm": 7.984750270843506,
      "learning_rate": 4.9270377319157805e-05,
      "loss": 0.1266,
      "step": 70
    },
    {
      "epoch": 0.050031269543464665,
      "grad_norm": 0.18168975412845612,
      "learning_rate": 4.916614550760892e-05,
      "loss": 0.083,
      "step": 80
    },
    {
      "epoch": 0.05628517823639775,
      "grad_norm": 3.23276686668396,
      "learning_rate": 4.906191369606004e-05,
      "loss": 0.0512,
      "step": 90
    },
    {
      "epoch": 0.06253908692933083,
      "grad_norm": 9.676409721374512,
      "learning_rate": 4.8957681884511155e-05,
      "loss": 0.0884,
      "step": 100
    },
    {
      "epoch": 0.06879299562226392,
      "grad_norm": 0.3160267174243927,
      "learning_rate": 4.885345007296227e-05,
      "loss": 0.0527,
      "step": 110
    },
    {
      "epoch": 0.075046904315197,
      "grad_norm": 4.140906810760498,
      "learning_rate": 4.874921826141339e-05,
      "loss": 0.0502,
      "step": 120
    },
    {
      "epoch": 0.08130081300813008,
      "grad_norm": 0.10053111612796783,
      "learning_rate": 4.86449864498645e-05,
      "loss": 0.0415,
      "step": 130
    },
    {
      "epoch": 0.08755472170106317,
      "grad_norm": 0.6729695796966553,
      "learning_rate": 4.8540754638315615e-05,
      "loss": 0.0658,
      "step": 140
    },
    {
      "epoch": 0.09380863039399624,
      "grad_norm": 0.06278358399868011,
      "learning_rate": 4.843652282676673e-05,
      "loss": 0.0435,
      "step": 150
    },
    {
      "epoch": 0.10006253908692933,
      "grad_norm": 0.6027106642723083,
      "learning_rate": 4.833229101521785e-05,
      "loss": 0.1804,
      "step": 160
    },
    {
      "epoch": 0.10631644777986242,
      "grad_norm": 1.0174719095230103,
      "learning_rate": 4.8228059203668965e-05,
      "loss": 0.1179,
      "step": 170
    },
    {
      "epoch": 0.1125703564727955,
      "grad_norm": 0.07532531768083572,
      "learning_rate": 4.812382739212008e-05,
      "loss": 0.0447,
      "step": 180
    },
    {
      "epoch": 0.11882426516572858,
      "grad_norm": 0.23015403747558594,
      "learning_rate": 4.801959558057119e-05,
      "loss": 0.1205,
      "step": 190
    },
    {
      "epoch": 0.12507817385866166,
      "grad_norm": 3.0194406509399414,
      "learning_rate": 4.791536376902231e-05,
      "loss": 0.0479,
      "step": 200
    },
    {
      "epoch": 0.13133208255159476,
      "grad_norm": 1.0671087503433228,
      "learning_rate": 4.781113195747342e-05,
      "loss": 0.0318,
      "step": 210
    },
    {
      "epoch": 0.13758599124452783,
      "grad_norm": 0.08635252714157104,
      "learning_rate": 4.770690014592454e-05,
      "loss": 0.1041,
      "step": 220
    },
    {
      "epoch": 0.1438398999374609,
      "grad_norm": 0.10599970817565918,
      "learning_rate": 4.760266833437566e-05,
      "loss": 0.0619,
      "step": 230
    },
    {
      "epoch": 0.150093808630394,
      "grad_norm": 6.836989402770996,
      "learning_rate": 4.749843652282677e-05,
      "loss": 0.1333,
      "step": 240
    },
    {
      "epoch": 0.15634771732332708,
      "grad_norm": 0.9700784087181091,
      "learning_rate": 4.7394204711277884e-05,
      "loss": 0.0907,
      "step": 250
    },
    {
      "epoch": 0.16260162601626016,
      "grad_norm": 0.1064070612192154,
      "learning_rate": 4.7289972899729e-05,
      "loss": 0.0971,
      "step": 260
    },
    {
      "epoch": 0.16885553470919323,
      "grad_norm": 11.843490600585938,
      "learning_rate": 4.718574108818011e-05,
      "loss": 0.0984,
      "step": 270
    },
    {
      "epoch": 0.17510944340212634,
      "grad_norm": 0.44960957765579224,
      "learning_rate": 4.708150927663123e-05,
      "loss": 0.0479,
      "step": 280
    },
    {
      "epoch": 0.1813633520950594,
      "grad_norm": 0.7914291024208069,
      "learning_rate": 4.697727746508235e-05,
      "loss": 0.0547,
      "step": 290
    },
    {
      "epoch": 0.18761726078799248,
      "grad_norm": 0.12643112242221832,
      "learning_rate": 4.687304565353346e-05,
      "loss": 0.0802,
      "step": 300
    },
    {
      "epoch": 0.1938711694809256,
      "grad_norm": 0.2583915889263153,
      "learning_rate": 4.676881384198458e-05,
      "loss": 0.1113,
      "step": 310
    },
    {
      "epoch": 0.20012507817385866,
      "grad_norm": 17.662296295166016,
      "learning_rate": 4.666458203043569e-05,
      "loss": 0.0262,
      "step": 320
    },
    {
      "epoch": 0.20637898686679174,
      "grad_norm": 7.00095796585083,
      "learning_rate": 4.6560350218886804e-05,
      "loss": 0.1184,
      "step": 330
    },
    {
      "epoch": 0.21263289555972484,
      "grad_norm": 0.14874887466430664,
      "learning_rate": 4.645611840733792e-05,
      "loss": 0.1073,
      "step": 340
    },
    {
      "epoch": 0.2188868042526579,
      "grad_norm": 6.306918144226074,
      "learning_rate": 4.635188659578904e-05,
      "loss": 0.0287,
      "step": 350
    },
    {
      "epoch": 0.225140712945591,
      "grad_norm": 0.20109951496124268,
      "learning_rate": 4.6247654784240154e-05,
      "loss": 0.0698,
      "step": 360
    },
    {
      "epoch": 0.2313946216385241,
      "grad_norm": 0.09608227014541626,
      "learning_rate": 4.614342297269127e-05,
      "loss": 0.0486,
      "step": 370
    },
    {
      "epoch": 0.23764853033145716,
      "grad_norm": 15.688694953918457,
      "learning_rate": 4.603919116114238e-05,
      "loss": 0.1249,
      "step": 380
    },
    {
      "epoch": 0.24390243902439024,
      "grad_norm": 9.634652137756348,
      "learning_rate": 4.59349593495935e-05,
      "loss": 0.0956,
      "step": 390
    },
    {
      "epoch": 0.2501563477173233,
      "grad_norm": 7.74387788772583,
      "learning_rate": 4.5830727538044614e-05,
      "loss": 0.111,
      "step": 400
    },
    {
      "epoch": 0.2564102564102564,
      "grad_norm": 13.138375282287598,
      "learning_rate": 4.572649572649573e-05,
      "loss": 0.1092,
      "step": 410
    },
    {
      "epoch": 0.2626641651031895,
      "grad_norm": 5.915304183959961,
      "learning_rate": 4.562226391494685e-05,
      "loss": 0.0953,
      "step": 420
    },
    {
      "epoch": 0.2689180737961226,
      "grad_norm": 6.373575210571289,
      "learning_rate": 4.5518032103397964e-05,
      "loss": 0.0574,
      "step": 430
    },
    {
      "epoch": 0.27517198248905567,
      "grad_norm": 6.757223606109619,
      "learning_rate": 4.541380029184907e-05,
      "loss": 0.0815,
      "step": 440
    },
    {
      "epoch": 0.28142589118198874,
      "grad_norm": 0.21939584612846375,
      "learning_rate": 4.530956848030019e-05,
      "loss": 0.0448,
      "step": 450
    },
    {
      "epoch": 0.2876797998749218,
      "grad_norm": 13.826632499694824,
      "learning_rate": 4.52053366687513e-05,
      "loss": 0.0575,
      "step": 460
    },
    {
      "epoch": 0.2939337085678549,
      "grad_norm": 10.636237144470215,
      "learning_rate": 4.5101104857202417e-05,
      "loss": 0.0768,
      "step": 470
    },
    {
      "epoch": 0.300187617260788,
      "grad_norm": 2.1250033378601074,
      "learning_rate": 4.499687304565354e-05,
      "loss": 0.1001,
      "step": 480
    },
    {
      "epoch": 0.3064415259537211,
      "grad_norm": 8.72056770324707,
      "learning_rate": 4.489264123410465e-05,
      "loss": 0.1731,
      "step": 490
    },
    {
      "epoch": 0.31269543464665417,
      "grad_norm": 7.16171932220459,
      "learning_rate": 4.4788409422555766e-05,
      "loss": 0.0986,
      "step": 500
    },
    {
      "epoch": 0.31894934333958724,
      "grad_norm": 0.383806049823761,
      "learning_rate": 4.468417761100688e-05,
      "loss": 0.0403,
      "step": 510
    },
    {
      "epoch": 0.3252032520325203,
      "grad_norm": 0.0500686839222908,
      "learning_rate": 4.457994579945799e-05,
      "loss": 0.062,
      "step": 520
    },
    {
      "epoch": 0.3314571607254534,
      "grad_norm": 9.560412406921387,
      "learning_rate": 4.447571398790911e-05,
      "loss": 0.1072,
      "step": 530
    },
    {
      "epoch": 0.33771106941838647,
      "grad_norm": 1.650088906288147,
      "learning_rate": 4.4371482176360226e-05,
      "loss": 0.1248,
      "step": 540
    },
    {
      "epoch": 0.3439649781113196,
      "grad_norm": 0.08336286246776581,
      "learning_rate": 4.426725036481134e-05,
      "loss": 0.0623,
      "step": 550
    },
    {
      "epoch": 0.35021888680425267,
      "grad_norm": 0.07596894353628159,
      "learning_rate": 4.416301855326246e-05,
      "loss": 0.0926,
      "step": 560
    },
    {
      "epoch": 0.35647279549718575,
      "grad_norm": 0.1307000368833542,
      "learning_rate": 4.4058786741713576e-05,
      "loss": 0.0637,
      "step": 570
    },
    {
      "epoch": 0.3627267041901188,
      "grad_norm": 0.733466386795044,
      "learning_rate": 4.3954554930164686e-05,
      "loss": 0.0177,
      "step": 580
    },
    {
      "epoch": 0.3689806128830519,
      "grad_norm": 0.17071810364723206,
      "learning_rate": 4.38503231186158e-05,
      "loss": 0.0699,
      "step": 590
    },
    {
      "epoch": 0.37523452157598497,
      "grad_norm": 5.092574596405029,
      "learning_rate": 4.374609130706692e-05,
      "loss": 0.0155,
      "step": 600
    },
    {
      "epoch": 0.3814884302689181,
      "grad_norm": 0.08063679188489914,
      "learning_rate": 4.3641859495518036e-05,
      "loss": 0.0213,
      "step": 610
    },
    {
      "epoch": 0.3877423389618512,
      "grad_norm": 0.08075270801782608,
      "learning_rate": 4.353762768396915e-05,
      "loss": 0.0526,
      "step": 620
    },
    {
      "epoch": 0.39399624765478425,
      "grad_norm": 1.1400920152664185,
      "learning_rate": 4.343339587242026e-05,
      "loss": 0.1074,
      "step": 630
    },
    {
      "epoch": 0.4002501563477173,
      "grad_norm": 5.785594463348389,
      "learning_rate": 4.332916406087138e-05,
      "loss": 0.0961,
      "step": 640
    },
    {
      "epoch": 0.4065040650406504,
      "grad_norm": 10.610084533691406,
      "learning_rate": 4.3224932249322496e-05,
      "loss": 0.1521,
      "step": 650
    },
    {
      "epoch": 0.41275797373358347,
      "grad_norm": 2.0674214363098145,
      "learning_rate": 4.312070043777361e-05,
      "loss": 0.039,
      "step": 660
    },
    {
      "epoch": 0.41901188242651655,
      "grad_norm": 0.42433595657348633,
      "learning_rate": 4.301646862622473e-05,
      "loss": 0.0563,
      "step": 670
    },
    {
      "epoch": 0.4252657911194497,
      "grad_norm": 0.4235002100467682,
      "learning_rate": 4.2912236814675846e-05,
      "loss": 0.1504,
      "step": 680
    },
    {
      "epoch": 0.43151969981238275,
      "grad_norm": 0.1293834149837494,
      "learning_rate": 4.2808005003126955e-05,
      "loss": 0.0292,
      "step": 690
    },
    {
      "epoch": 0.4377736085053158,
      "grad_norm": 12.587324142456055,
      "learning_rate": 4.270377319157807e-05,
      "loss": 0.0792,
      "step": 700
    },
    {
      "epoch": 0.4440275171982489,
      "grad_norm": 0.18624401092529297,
      "learning_rate": 4.259954138002918e-05,
      "loss": 0.0872,
      "step": 710
    },
    {
      "epoch": 0.450281425891182,
      "grad_norm": 1.7729555368423462,
      "learning_rate": 4.24953095684803e-05,
      "loss": 0.0108,
      "step": 720
    },
    {
      "epoch": 0.45653533458411505,
      "grad_norm": 0.0633101537823677,
      "learning_rate": 4.239107775693142e-05,
      "loss": 0.0961,
      "step": 730
    },
    {
      "epoch": 0.4627892432770482,
      "grad_norm": 0.6789349913597107,
      "learning_rate": 4.228684594538253e-05,
      "loss": 0.0329,
      "step": 740
    },
    {
      "epoch": 0.46904315196998125,
      "grad_norm": 0.7463671565055847,
      "learning_rate": 4.218261413383365e-05,
      "loss": 0.0249,
      "step": 750
    },
    {
      "epoch": 0.47529706066291433,
      "grad_norm": 2.6279168128967285,
      "learning_rate": 4.2078382322284765e-05,
      "loss": 0.0044,
      "step": 760
    },
    {
      "epoch": 0.4815509693558474,
      "grad_norm": 0.03604523092508316,
      "learning_rate": 4.1974150510735875e-05,
      "loss": 0.0782,
      "step": 770
    },
    {
      "epoch": 0.4878048780487805,
      "grad_norm": 0.036616433411836624,
      "learning_rate": 4.186991869918699e-05,
      "loss": 0.1576,
      "step": 780
    },
    {
      "epoch": 0.49405878674171355,
      "grad_norm": 0.09100951999425888,
      "learning_rate": 4.176568688763811e-05,
      "loss": 0.0281,
      "step": 790
    },
    {
      "epoch": 0.5003126954346466,
      "grad_norm": 0.057935066521167755,
      "learning_rate": 4.1661455076089225e-05,
      "loss": 0.0658,
      "step": 800
    },
    {
      "epoch": 0.5065666041275797,
      "grad_norm": 8.132308959960938,
      "learning_rate": 4.155722326454034e-05,
      "loss": 0.0739,
      "step": 810
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 0.1469096690416336,
      "learning_rate": 4.145299145299146e-05,
      "loss": 0.1112,
      "step": 820
    },
    {
      "epoch": 0.5190744215134458,
      "grad_norm": 6.589786529541016,
      "learning_rate": 4.134875964144257e-05,
      "loss": 0.0727,
      "step": 830
    },
    {
      "epoch": 0.525328330206379,
      "grad_norm": 1.3200281858444214,
      "learning_rate": 4.1244527829893685e-05,
      "loss": 0.0436,
      "step": 840
    },
    {
      "epoch": 0.5315822388993121,
      "grad_norm": 28.305082321166992,
      "learning_rate": 4.11402960183448e-05,
      "loss": 0.0842,
      "step": 850
    },
    {
      "epoch": 0.5378361475922452,
      "grad_norm": 0.06538552790880203,
      "learning_rate": 4.103606420679592e-05,
      "loss": 0.092,
      "step": 860
    },
    {
      "epoch": 0.5440900562851783,
      "grad_norm": 0.14088158309459686,
      "learning_rate": 4.0931832395247035e-05,
      "loss": 0.0598,
      "step": 870
    },
    {
      "epoch": 0.5503439649781113,
      "grad_norm": 0.06562728434801102,
      "learning_rate": 4.0827600583698144e-05,
      "loss": 0.1129,
      "step": 880
    },
    {
      "epoch": 0.5565978736710444,
      "grad_norm": 1.05733323097229,
      "learning_rate": 4.072336877214926e-05,
      "loss": 0.0669,
      "step": 890
    },
    {
      "epoch": 0.5628517823639775,
      "grad_norm": 17.93256378173828,
      "learning_rate": 4.061913696060038e-05,
      "loss": 0.0912,
      "step": 900
    },
    {
      "epoch": 0.5691056910569106,
      "grad_norm": 9.491959571838379,
      "learning_rate": 4.051490514905149e-05,
      "loss": 0.0403,
      "step": 910
    },
    {
      "epoch": 0.5753595997498436,
      "grad_norm": 0.04010415077209473,
      "learning_rate": 4.041067333750261e-05,
      "loss": 0.1284,
      "step": 920
    },
    {
      "epoch": 0.5816135084427767,
      "grad_norm": 0.06082770228385925,
      "learning_rate": 4.030644152595373e-05,
      "loss": 0.164,
      "step": 930
    },
    {
      "epoch": 0.5878674171357098,
      "grad_norm": 0.09021168947219849,
      "learning_rate": 4.020220971440484e-05,
      "loss": 0.0896,
      "step": 940
    },
    {
      "epoch": 0.5941213258286429,
      "grad_norm": 1.4429004192352295,
      "learning_rate": 4.0097977902855954e-05,
      "loss": 0.0791,
      "step": 950
    },
    {
      "epoch": 0.600375234521576,
      "grad_norm": 2.4441921710968018,
      "learning_rate": 3.9993746091307064e-05,
      "loss": 0.049,
      "step": 960
    },
    {
      "epoch": 0.6066291432145091,
      "grad_norm": 15.107951164245605,
      "learning_rate": 3.988951427975818e-05,
      "loss": 0.1308,
      "step": 970
    },
    {
      "epoch": 0.6128830519074422,
      "grad_norm": 7.791202068328857,
      "learning_rate": 3.9785282468209304e-05,
      "loss": 0.0437,
      "step": 980
    },
    {
      "epoch": 0.6191369606003753,
      "grad_norm": 3.442681074142456,
      "learning_rate": 3.9681050656660414e-05,
      "loss": 0.0486,
      "step": 990
    },
    {
      "epoch": 0.6253908692933083,
      "grad_norm": 4.004490375518799,
      "learning_rate": 3.957681884511153e-05,
      "loss": 0.0297,
      "step": 1000
    },
    {
      "epoch": 0.6316447779862414,
      "grad_norm": 0.11028594523668289,
      "learning_rate": 3.947258703356265e-05,
      "loss": 0.0108,
      "step": 1010
    },
    {
      "epoch": 0.6378986866791745,
      "grad_norm": 0.06608215719461441,
      "learning_rate": 3.936835522201376e-05,
      "loss": 0.0531,
      "step": 1020
    },
    {
      "epoch": 0.6441525953721076,
      "grad_norm": 0.042441170662641525,
      "learning_rate": 3.9264123410464874e-05,
      "loss": 0.1287,
      "step": 1030
    },
    {
      "epoch": 0.6504065040650406,
      "grad_norm": 0.04160606116056442,
      "learning_rate": 3.915989159891599e-05,
      "loss": 0.0392,
      "step": 1040
    },
    {
      "epoch": 0.6566604127579737,
      "grad_norm": 0.11635306477546692,
      "learning_rate": 3.905565978736711e-05,
      "loss": 0.1194,
      "step": 1050
    },
    {
      "epoch": 0.6629143214509068,
      "grad_norm": 0.27154430747032166,
      "learning_rate": 3.8951427975818223e-05,
      "loss": 0.0414,
      "step": 1060
    },
    {
      "epoch": 0.6691682301438399,
      "grad_norm": 0.038260530680418015,
      "learning_rate": 3.884719616426934e-05,
      "loss": 0.0441,
      "step": 1070
    },
    {
      "epoch": 0.6754221388367729,
      "grad_norm": 0.08210691809654236,
      "learning_rate": 3.874296435272045e-05,
      "loss": 0.043,
      "step": 1080
    },
    {
      "epoch": 0.6816760475297061,
      "grad_norm": 0.04930547624826431,
      "learning_rate": 3.863873254117157e-05,
      "loss": 0.1496,
      "step": 1090
    },
    {
      "epoch": 0.6879299562226392,
      "grad_norm": 27.380029678344727,
      "learning_rate": 3.853450072962268e-05,
      "loss": 0.1203,
      "step": 1100
    },
    {
      "epoch": 0.6941838649155723,
      "grad_norm": 0.049737993627786636,
      "learning_rate": 3.84302689180738e-05,
      "loss": 0.0439,
      "step": 1110
    },
    {
      "epoch": 0.7004377736085053,
      "grad_norm": 0.6220563650131226,
      "learning_rate": 3.8326037106524917e-05,
      "loss": 0.0214,
      "step": 1120
    },
    {
      "epoch": 0.7066916823014384,
      "grad_norm": 0.05965579301118851,
      "learning_rate": 3.8221805294976026e-05,
      "loss": 0.0235,
      "step": 1130
    },
    {
      "epoch": 0.7129455909943715,
      "grad_norm": 0.06679427623748779,
      "learning_rate": 3.811757348342714e-05,
      "loss": 0.0392,
      "step": 1140
    },
    {
      "epoch": 0.7191994996873046,
      "grad_norm": 1.7009018659591675,
      "learning_rate": 3.801334167187826e-05,
      "loss": 0.0392,
      "step": 1150
    },
    {
      "epoch": 0.7254534083802376,
      "grad_norm": 0.6108495593070984,
      "learning_rate": 3.790910986032937e-05,
      "loss": 0.1139,
      "step": 1160
    },
    {
      "epoch": 0.7317073170731707,
      "grad_norm": 0.031215891242027283,
      "learning_rate": 3.780487804878049e-05,
      "loss": 0.1591,
      "step": 1170
    },
    {
      "epoch": 0.7379612257661038,
      "grad_norm": 0.11882312595844269,
      "learning_rate": 3.770064623723161e-05,
      "loss": 0.0524,
      "step": 1180
    },
    {
      "epoch": 0.7442151344590369,
      "grad_norm": 0.036917008459568024,
      "learning_rate": 3.759641442568272e-05,
      "loss": 0.0535,
      "step": 1190
    },
    {
      "epoch": 0.7504690431519699,
      "grad_norm": 3.584357738494873,
      "learning_rate": 3.7492182614133836e-05,
      "loss": 0.0279,
      "step": 1200
    },
    {
      "epoch": 0.756722951844903,
      "grad_norm": 0.03357454016804695,
      "learning_rate": 3.738795080258495e-05,
      "loss": 0.0858,
      "step": 1210
    },
    {
      "epoch": 0.7629768605378362,
      "grad_norm": 10.675154685974121,
      "learning_rate": 3.728371899103606e-05,
      "loss": 0.027,
      "step": 1220
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 0.04237139970064163,
      "learning_rate": 3.717948717948718e-05,
      "loss": 0.0386,
      "step": 1230
    },
    {
      "epoch": 0.7754846779237023,
      "grad_norm": 0.10772591829299927,
      "learning_rate": 3.7075255367938296e-05,
      "loss": 0.0495,
      "step": 1240
    },
    {
      "epoch": 0.7817385866166354,
      "grad_norm": 11.118101119995117,
      "learning_rate": 3.697102355638941e-05,
      "loss": 0.0424,
      "step": 1250
    },
    {
      "epoch": 0.7879924953095685,
      "grad_norm": 0.10572243481874466,
      "learning_rate": 3.686679174484053e-05,
      "loss": 0.0649,
      "step": 1260
    },
    {
      "epoch": 0.7942464040025016,
      "grad_norm": 0.027645647525787354,
      "learning_rate": 3.676255993329164e-05,
      "loss": 0.0422,
      "step": 1270
    },
    {
      "epoch": 0.8005003126954346,
      "grad_norm": 7.8873701095581055,
      "learning_rate": 3.6658328121742756e-05,
      "loss": 0.0951,
      "step": 1280
    },
    {
      "epoch": 0.8067542213883677,
      "grad_norm": 0.042448740452528,
      "learning_rate": 3.655409631019387e-05,
      "loss": 0.034,
      "step": 1290
    },
    {
      "epoch": 0.8130081300813008,
      "grad_norm": 0.08420506864786148,
      "learning_rate": 3.644986449864499e-05,
      "loss": 0.0791,
      "step": 1300
    },
    {
      "epoch": 0.8192620387742339,
      "grad_norm": 0.03296882286667824,
      "learning_rate": 3.6345632687096105e-05,
      "loss": 0.117,
      "step": 1310
    },
    {
      "epoch": 0.8255159474671669,
      "grad_norm": 3.50466251373291,
      "learning_rate": 3.624140087554722e-05,
      "loss": 0.0587,
      "step": 1320
    },
    {
      "epoch": 0.8317698561601,
      "grad_norm": 11.576956748962402,
      "learning_rate": 3.613716906399833e-05,
      "loss": 0.0512,
      "step": 1330
    },
    {
      "epoch": 0.8380237648530331,
      "grad_norm": 0.04870525747537613,
      "learning_rate": 3.603293725244945e-05,
      "loss": 0.1568,
      "step": 1340
    },
    {
      "epoch": 0.8442776735459663,
      "grad_norm": 3.14689040184021,
      "learning_rate": 3.5928705440900565e-05,
      "loss": 0.1214,
      "step": 1350
    },
    {
      "epoch": 0.8505315822388994,
      "grad_norm": 17.910242080688477,
      "learning_rate": 3.582447362935168e-05,
      "loss": 0.1309,
      "step": 1360
    },
    {
      "epoch": 0.8567854909318324,
      "grad_norm": 12.026419639587402,
      "learning_rate": 3.57202418178028e-05,
      "loss": 0.0563,
      "step": 1370
    },
    {
      "epoch": 0.8630393996247655,
      "grad_norm": 0.07085279375314713,
      "learning_rate": 3.561601000625391e-05,
      "loss": 0.0408,
      "step": 1380
    },
    {
      "epoch": 0.8692933083176986,
      "grad_norm": 1.008329153060913,
      "learning_rate": 3.5511778194705025e-05,
      "loss": 0.079,
      "step": 1390
    },
    {
      "epoch": 0.8755472170106317,
      "grad_norm": 10.595829010009766,
      "learning_rate": 3.540754638315614e-05,
      "loss": 0.0969,
      "step": 1400
    },
    {
      "epoch": 0.8818011257035647,
      "grad_norm": 19.474098205566406,
      "learning_rate": 3.530331457160725e-05,
      "loss": 0.0129,
      "step": 1410
    },
    {
      "epoch": 0.8880550343964978,
      "grad_norm": 6.5079345703125,
      "learning_rate": 3.5199082760058375e-05,
      "loss": 0.0937,
      "step": 1420
    },
    {
      "epoch": 0.8943089430894309,
      "grad_norm": 0.10278644412755966,
      "learning_rate": 3.509485094850949e-05,
      "loss": 0.0609,
      "step": 1430
    },
    {
      "epoch": 0.900562851782364,
      "grad_norm": 0.3874758780002594,
      "learning_rate": 3.49906191369606e-05,
      "loss": 0.0434,
      "step": 1440
    },
    {
      "epoch": 0.906816760475297,
      "grad_norm": 5.10392427444458,
      "learning_rate": 3.488638732541172e-05,
      "loss": 0.0733,
      "step": 1450
    },
    {
      "epoch": 0.9130706691682301,
      "grad_norm": 0.3235251009464264,
      "learning_rate": 3.4782155513862835e-05,
      "loss": 0.1076,
      "step": 1460
    },
    {
      "epoch": 0.9193245778611632,
      "grad_norm": 0.0452614426612854,
      "learning_rate": 3.4677923702313945e-05,
      "loss": 0.0793,
      "step": 1470
    },
    {
      "epoch": 0.9255784865540964,
      "grad_norm": 12.353853225708008,
      "learning_rate": 3.457369189076506e-05,
      "loss": 0.1126,
      "step": 1480
    },
    {
      "epoch": 0.9318323952470294,
      "grad_norm": 0.21806354820728302,
      "learning_rate": 3.446946007921618e-05,
      "loss": 0.2261,
      "step": 1490
    },
    {
      "epoch": 0.9380863039399625,
      "grad_norm": 0.08168236911296844,
      "learning_rate": 3.4365228267667294e-05,
      "loss": 0.0961,
      "step": 1500
    },
    {
      "epoch": 0.9443402126328956,
      "grad_norm": 0.2565726637840271,
      "learning_rate": 3.426099645611841e-05,
      "loss": 0.0525,
      "step": 1510
    },
    {
      "epoch": 0.9505941213258287,
      "grad_norm": 9.767847061157227,
      "learning_rate": 3.415676464456952e-05,
      "loss": 0.0738,
      "step": 1520
    },
    {
      "epoch": 0.9568480300187617,
      "grad_norm": 5.232820987701416,
      "learning_rate": 3.405253283302064e-05,
      "loss": 0.0772,
      "step": 1530
    },
    {
      "epoch": 0.9631019387116948,
      "grad_norm": 1.5355411767959595,
      "learning_rate": 3.3948301021471754e-05,
      "loss": 0.0607,
      "step": 1540
    },
    {
      "epoch": 0.9693558474046279,
      "grad_norm": 2.879824161529541,
      "learning_rate": 3.384406920992287e-05,
      "loss": 0.0422,
      "step": 1550
    },
    {
      "epoch": 0.975609756097561,
      "grad_norm": 0.21715925633907318,
      "learning_rate": 3.373983739837399e-05,
      "loss": 0.0562,
      "step": 1560
    },
    {
      "epoch": 0.981863664790494,
      "grad_norm": 14.328224182128906,
      "learning_rate": 3.3635605586825104e-05,
      "loss": 0.1179,
      "step": 1570
    },
    {
      "epoch": 0.9881175734834271,
      "grad_norm": 0.6427140831947327,
      "learning_rate": 3.3531373775276214e-05,
      "loss": 0.0759,
      "step": 1580
    },
    {
      "epoch": 0.9943714821763602,
      "grad_norm": 0.0810517817735672,
      "learning_rate": 3.342714196372733e-05,
      "loss": 0.0688,
      "step": 1590
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9576098858126075,
      "eval_loss": 0.16604188084602356,
      "eval_runtime": 9.6112,
      "eval_samples_per_second": 665.163,
      "eval_steps_per_second": 41.618,
      "step": 1599
    },
    {
      "epoch": 1.0006253908692933,
      "grad_norm": 0.32042133808135986,
      "learning_rate": 3.332291015217844e-05,
      "loss": 0.1593,
      "step": 1600
    },
    {
      "epoch": 1.0068792995622264,
      "grad_norm": 2.5184946060180664,
      "learning_rate": 3.3218678340629564e-05,
      "loss": 0.1122,
      "step": 1610
    },
    {
      "epoch": 1.0131332082551594,
      "grad_norm": 10.624920845031738,
      "learning_rate": 3.311444652908068e-05,
      "loss": 0.1281,
      "step": 1620
    },
    {
      "epoch": 1.0193871169480926,
      "grad_norm": 0.062354687601327896,
      "learning_rate": 3.301021471753179e-05,
      "loss": 0.0849,
      "step": 1630
    },
    {
      "epoch": 1.0256410256410255,
      "grad_norm": 5.642749786376953,
      "learning_rate": 3.290598290598291e-05,
      "loss": 0.0417,
      "step": 1640
    },
    {
      "epoch": 1.0318949343339587,
      "grad_norm": 26.59457015991211,
      "learning_rate": 3.2801751094434024e-05,
      "loss": 0.0696,
      "step": 1650
    },
    {
      "epoch": 1.038148843026892,
      "grad_norm": 0.20067228376865387,
      "learning_rate": 3.2697519282885134e-05,
      "loss": 0.14,
      "step": 1660
    },
    {
      "epoch": 1.0444027517198249,
      "grad_norm": 0.05937497690320015,
      "learning_rate": 3.259328747133625e-05,
      "loss": 0.0187,
      "step": 1670
    },
    {
      "epoch": 1.050656660412758,
      "grad_norm": 0.08108001202344894,
      "learning_rate": 3.2489055659787374e-05,
      "loss": 0.0219,
      "step": 1680
    },
    {
      "epoch": 1.056910569105691,
      "grad_norm": 8.420589447021484,
      "learning_rate": 3.2384823848238483e-05,
      "loss": 0.0601,
      "step": 1690
    },
    {
      "epoch": 1.0631644777986242,
      "grad_norm": 0.5731619596481323,
      "learning_rate": 3.22805920366896e-05,
      "loss": 0.1324,
      "step": 1700
    },
    {
      "epoch": 1.0694183864915572,
      "grad_norm": 26.9782772064209,
      "learning_rate": 3.217636022514072e-05,
      "loss": 0.0647,
      "step": 1710
    },
    {
      "epoch": 1.0756722951844904,
      "grad_norm": 0.07661382853984833,
      "learning_rate": 3.2072128413591827e-05,
      "loss": 0.061,
      "step": 1720
    },
    {
      "epoch": 1.0819262038774233,
      "grad_norm": 0.06333530694246292,
      "learning_rate": 3.196789660204294e-05,
      "loss": 0.1536,
      "step": 1730
    },
    {
      "epoch": 1.0881801125703565,
      "grad_norm": 8.301142692565918,
      "learning_rate": 3.186366479049406e-05,
      "loss": 0.1139,
      "step": 1740
    },
    {
      "epoch": 1.0944340212632895,
      "grad_norm": 14.34422492980957,
      "learning_rate": 3.1759432978945176e-05,
      "loss": 0.1253,
      "step": 1750
    },
    {
      "epoch": 1.1006879299562227,
      "grad_norm": 0.8462964296340942,
      "learning_rate": 3.165520116739629e-05,
      "loss": 0.056,
      "step": 1760
    },
    {
      "epoch": 1.1069418386491556,
      "grad_norm": 0.1978406012058258,
      "learning_rate": 3.15509693558474e-05,
      "loss": 0.0377,
      "step": 1770
    },
    {
      "epoch": 1.1131957473420888,
      "grad_norm": 0.04828416183590889,
      "learning_rate": 3.144673754429852e-05,
      "loss": 0.0196,
      "step": 1780
    },
    {
      "epoch": 1.1194496560350218,
      "grad_norm": 0.09661304950714111,
      "learning_rate": 3.1342505732749636e-05,
      "loss": 0.0971,
      "step": 1790
    },
    {
      "epoch": 1.125703564727955,
      "grad_norm": 12.195548057556152,
      "learning_rate": 3.123827392120075e-05,
      "loss": 0.08,
      "step": 1800
    },
    {
      "epoch": 1.1319574734208881,
      "grad_norm": 0.1276957392692566,
      "learning_rate": 3.113404210965187e-05,
      "loss": 0.1639,
      "step": 1810
    },
    {
      "epoch": 1.1382113821138211,
      "grad_norm": 19.64949607849121,
      "learning_rate": 3.1029810298102986e-05,
      "loss": 0.0743,
      "step": 1820
    },
    {
      "epoch": 1.1444652908067543,
      "grad_norm": 0.593393862247467,
      "learning_rate": 3.0925578486554096e-05,
      "loss": 0.1215,
      "step": 1830
    },
    {
      "epoch": 1.1507191994996873,
      "grad_norm": 13.246689796447754,
      "learning_rate": 3.082134667500521e-05,
      "loss": 0.0308,
      "step": 1840
    },
    {
      "epoch": 1.1569731081926204,
      "grad_norm": 5.691676139831543,
      "learning_rate": 3.071711486345633e-05,
      "loss": 0.0243,
      "step": 1850
    },
    {
      "epoch": 1.1632270168855534,
      "grad_norm": 0.06832911819219589,
      "learning_rate": 3.0612883051907446e-05,
      "loss": 0.0503,
      "step": 1860
    },
    {
      "epoch": 1.1694809255784866,
      "grad_norm": 13.110079765319824,
      "learning_rate": 3.050865124035856e-05,
      "loss": 0.1,
      "step": 1870
    },
    {
      "epoch": 1.1757348342714196,
      "grad_norm": 2.8341612815856934,
      "learning_rate": 3.0404419428809672e-05,
      "loss": 0.0827,
      "step": 1880
    },
    {
      "epoch": 1.1819887429643527,
      "grad_norm": 0.6595374345779419,
      "learning_rate": 3.030018761726079e-05,
      "loss": 0.0711,
      "step": 1890
    },
    {
      "epoch": 1.1882426516572857,
      "grad_norm": 1.1508363485336304,
      "learning_rate": 3.0195955805711906e-05,
      "loss": 0.2097,
      "step": 1900
    },
    {
      "epoch": 1.194496560350219,
      "grad_norm": 4.438155174255371,
      "learning_rate": 3.009172399416302e-05,
      "loss": 0.1382,
      "step": 1910
    },
    {
      "epoch": 1.200750469043152,
      "grad_norm": 0.12433652579784393,
      "learning_rate": 2.9987492182614136e-05,
      "loss": 0.0361,
      "step": 1920
    },
    {
      "epoch": 1.207004377736085,
      "grad_norm": 0.2939240336418152,
      "learning_rate": 2.9883260371065252e-05,
      "loss": 0.043,
      "step": 1930
    },
    {
      "epoch": 1.2132582864290182,
      "grad_norm": 0.09291815012693405,
      "learning_rate": 2.9779028559516365e-05,
      "loss": 0.0546,
      "step": 1940
    },
    {
      "epoch": 1.2195121951219512,
      "grad_norm": 1.5200806856155396,
      "learning_rate": 2.9674796747967482e-05,
      "loss": 0.0523,
      "step": 1950
    },
    {
      "epoch": 1.2257661038148844,
      "grad_norm": 0.20449618995189667,
      "learning_rate": 2.95705649364186e-05,
      "loss": 0.0215,
      "step": 1960
    },
    {
      "epoch": 1.2320200125078173,
      "grad_norm": 0.24836504459381104,
      "learning_rate": 2.9466333124869712e-05,
      "loss": 0.0488,
      "step": 1970
    },
    {
      "epoch": 1.2382739212007505,
      "grad_norm": 0.1387498527765274,
      "learning_rate": 2.936210131332083e-05,
      "loss": 0.0138,
      "step": 1980
    },
    {
      "epoch": 1.2445278298936835,
      "grad_norm": 0.2314121425151825,
      "learning_rate": 2.925786950177194e-05,
      "loss": 0.0547,
      "step": 1990
    },
    {
      "epoch": 1.2507817385866167,
      "grad_norm": 0.7722101211547852,
      "learning_rate": 2.915363769022306e-05,
      "loss": 0.0865,
      "step": 2000
    },
    {
      "epoch": 1.2570356472795496,
      "grad_norm": 17.089645385742188,
      "learning_rate": 2.9049405878674175e-05,
      "loss": 0.0973,
      "step": 2010
    },
    {
      "epoch": 1.2632895559724828,
      "grad_norm": 0.08141427487134933,
      "learning_rate": 2.8945174067125285e-05,
      "loss": 0.1037,
      "step": 2020
    },
    {
      "epoch": 1.269543464665416,
      "grad_norm": 0.2173476368188858,
      "learning_rate": 2.88409422555764e-05,
      "loss": 0.1795,
      "step": 2030
    },
    {
      "epoch": 1.275797373358349,
      "grad_norm": 9.99531078338623,
      "learning_rate": 2.873671044402752e-05,
      "loss": 0.1217,
      "step": 2040
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 0.15267162024974823,
      "learning_rate": 2.863247863247863e-05,
      "loss": 0.0429,
      "step": 2050
    },
    {
      "epoch": 1.2883051907442151,
      "grad_norm": 1.171288251876831,
      "learning_rate": 2.8528246820929748e-05,
      "loss": 0.05,
      "step": 2060
    },
    {
      "epoch": 1.2945590994371483,
      "grad_norm": 0.09460505098104477,
      "learning_rate": 2.8424015009380868e-05,
      "loss": 0.091,
      "step": 2070
    },
    {
      "epoch": 1.3008130081300813,
      "grad_norm": 16.638790130615234,
      "learning_rate": 2.8319783197831978e-05,
      "loss": 0.0523,
      "step": 2080
    },
    {
      "epoch": 1.3070669168230145,
      "grad_norm": 7.1604485511779785,
      "learning_rate": 2.8215551386283095e-05,
      "loss": 0.0865,
      "step": 2090
    },
    {
      "epoch": 1.3133208255159474,
      "grad_norm": 11.513717651367188,
      "learning_rate": 2.811131957473421e-05,
      "loss": 0.0726,
      "step": 2100
    },
    {
      "epoch": 1.3195747342088806,
      "grad_norm": 2.8481638431549072,
      "learning_rate": 2.8007087763185325e-05,
      "loss": 0.055,
      "step": 2110
    },
    {
      "epoch": 1.3258286429018136,
      "grad_norm": 0.1423216015100479,
      "learning_rate": 2.790285595163644e-05,
      "loss": 0.079,
      "step": 2120
    },
    {
      "epoch": 1.3320825515947468,
      "grad_norm": 0.5904778838157654,
      "learning_rate": 2.7798624140087554e-05,
      "loss": 0.0432,
      "step": 2130
    },
    {
      "epoch": 1.3383364602876797,
      "grad_norm": 9.761795043945312,
      "learning_rate": 2.769439232853867e-05,
      "loss": 0.079,
      "step": 2140
    },
    {
      "epoch": 1.344590368980613,
      "grad_norm": 13.438176155090332,
      "learning_rate": 2.7590160516989788e-05,
      "loss": 0.0609,
      "step": 2150
    },
    {
      "epoch": 1.3508442776735459,
      "grad_norm": 0.9065282940864563,
      "learning_rate": 2.74859287054409e-05,
      "loss": 0.0742,
      "step": 2160
    },
    {
      "epoch": 1.357098186366479,
      "grad_norm": 0.3811419606208801,
      "learning_rate": 2.7381696893892018e-05,
      "loss": 0.1315,
      "step": 2170
    },
    {
      "epoch": 1.3633520950594122,
      "grad_norm": 13.05263614654541,
      "learning_rate": 2.7277465082343134e-05,
      "loss": 0.114,
      "step": 2180
    },
    {
      "epoch": 1.3696060037523452,
      "grad_norm": 10.256935119628906,
      "learning_rate": 2.7173233270794247e-05,
      "loss": 0.1616,
      "step": 2190
    },
    {
      "epoch": 1.3758599124452782,
      "grad_norm": 26.4405517578125,
      "learning_rate": 2.7069001459245364e-05,
      "loss": 0.0217,
      "step": 2200
    },
    {
      "epoch": 1.3821138211382114,
      "grad_norm": 8.960905075073242,
      "learning_rate": 2.696476964769648e-05,
      "loss": 0.1465,
      "step": 2210
    },
    {
      "epoch": 1.3883677298311445,
      "grad_norm": 0.05003197118639946,
      "learning_rate": 2.6860537836147594e-05,
      "loss": 0.0872,
      "step": 2220
    },
    {
      "epoch": 1.3946216385240775,
      "grad_norm": 1.9361681938171387,
      "learning_rate": 2.675630602459871e-05,
      "loss": 0.1829,
      "step": 2230
    },
    {
      "epoch": 1.4008755472170107,
      "grad_norm": 0.058499790728092194,
      "learning_rate": 2.665207421304982e-05,
      "loss": 0.0687,
      "step": 2240
    },
    {
      "epoch": 1.4071294559099436,
      "grad_norm": 0.05791311711072922,
      "learning_rate": 2.6547842401500937e-05,
      "loss": 0.1161,
      "step": 2250
    },
    {
      "epoch": 1.4133833646028768,
      "grad_norm": 0.1257210224866867,
      "learning_rate": 2.6443610589952057e-05,
      "loss": 0.0764,
      "step": 2260
    },
    {
      "epoch": 1.4196372732958098,
      "grad_norm": 15.215116500854492,
      "learning_rate": 2.6339378778403167e-05,
      "loss": 0.0911,
      "step": 2270
    },
    {
      "epoch": 1.425891181988743,
      "grad_norm": 0.2139541655778885,
      "learning_rate": 2.6235146966854284e-05,
      "loss": 0.0258,
      "step": 2280
    },
    {
      "epoch": 1.4321450906816762,
      "grad_norm": 10.919672012329102,
      "learning_rate": 2.6130915155305404e-05,
      "loss": 0.1199,
      "step": 2290
    },
    {
      "epoch": 1.4383989993746091,
      "grad_norm": 5.081328868865967,
      "learning_rate": 2.6026683343756514e-05,
      "loss": 0.1346,
      "step": 2300
    },
    {
      "epoch": 1.444652908067542,
      "grad_norm": 7.403633117675781,
      "learning_rate": 2.592245153220763e-05,
      "loss": 0.0916,
      "step": 2310
    },
    {
      "epoch": 1.4509068167604753,
      "grad_norm": 0.5151103734970093,
      "learning_rate": 2.5818219720658747e-05,
      "loss": 0.0897,
      "step": 2320
    },
    {
      "epoch": 1.4571607254534085,
      "grad_norm": 0.6174492239952087,
      "learning_rate": 2.571398790910986e-05,
      "loss": 0.0357,
      "step": 2330
    },
    {
      "epoch": 1.4634146341463414,
      "grad_norm": 0.49356457591056824,
      "learning_rate": 2.5609756097560977e-05,
      "loss": 0.0417,
      "step": 2340
    },
    {
      "epoch": 1.4696685428392746,
      "grad_norm": 0.8909059762954712,
      "learning_rate": 2.5505524286012093e-05,
      "loss": 0.0704,
      "step": 2350
    },
    {
      "epoch": 1.4759224515322076,
      "grad_norm": 1.8421276807785034,
      "learning_rate": 2.5401292474463207e-05,
      "loss": 0.1548,
      "step": 2360
    },
    {
      "epoch": 1.4821763602251408,
      "grad_norm": 10.173219680786133,
      "learning_rate": 2.5297060662914323e-05,
      "loss": 0.1454,
      "step": 2370
    },
    {
      "epoch": 1.4884302689180737,
      "grad_norm": 18.288955688476562,
      "learning_rate": 2.5192828851365436e-05,
      "loss": 0.0914,
      "step": 2380
    },
    {
      "epoch": 1.494684177611007,
      "grad_norm": 3.7138915061950684,
      "learning_rate": 2.5088597039816553e-05,
      "loss": 0.0436,
      "step": 2390
    },
    {
      "epoch": 1.50093808630394,
      "grad_norm": 0.07434119284152985,
      "learning_rate": 2.4984365228267666e-05,
      "loss": 0.0426,
      "step": 2400
    },
    {
      "epoch": 1.507191994996873,
      "grad_norm": 29.999311447143555,
      "learning_rate": 2.4880133416718783e-05,
      "loss": 0.1631,
      "step": 2410
    },
    {
      "epoch": 1.513445903689806,
      "grad_norm": 17.219730377197266,
      "learning_rate": 2.47759016051699e-05,
      "loss": 0.0322,
      "step": 2420
    },
    {
      "epoch": 1.5196998123827392,
      "grad_norm": 20.619421005249023,
      "learning_rate": 2.4671669793621013e-05,
      "loss": 0.1463,
      "step": 2430
    },
    {
      "epoch": 1.5259537210756724,
      "grad_norm": 10.154913902282715,
      "learning_rate": 2.456743798207213e-05,
      "loss": 0.0996,
      "step": 2440
    },
    {
      "epoch": 1.5322076297686054,
      "grad_norm": 0.5900272727012634,
      "learning_rate": 2.4463206170523246e-05,
      "loss": 0.0744,
      "step": 2450
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 24.516210556030273,
      "learning_rate": 2.435897435897436e-05,
      "loss": 0.1011,
      "step": 2460
    },
    {
      "epoch": 1.5447154471544715,
      "grad_norm": 1.6901098489761353,
      "learning_rate": 2.4254742547425473e-05,
      "loss": 0.0875,
      "step": 2470
    },
    {
      "epoch": 1.5509693558474047,
      "grad_norm": 14.560423851013184,
      "learning_rate": 2.4150510735876593e-05,
      "loss": 0.0872,
      "step": 2480
    },
    {
      "epoch": 1.5572232645403377,
      "grad_norm": 0.08914842456579208,
      "learning_rate": 2.4046278924327706e-05,
      "loss": 0.205,
      "step": 2490
    },
    {
      "epoch": 1.5634771732332708,
      "grad_norm": 11.586012840270996,
      "learning_rate": 2.394204711277882e-05,
      "loss": 0.0308,
      "step": 2500
    },
    {
      "epoch": 1.569731081926204,
      "grad_norm": 54.59172439575195,
      "learning_rate": 2.383781530122994e-05,
      "loss": 0.0826,
      "step": 2510
    },
    {
      "epoch": 1.575984990619137,
      "grad_norm": 0.11092808097600937,
      "learning_rate": 2.3733583489681052e-05,
      "loss": 0.1193,
      "step": 2520
    },
    {
      "epoch": 1.58223889931207,
      "grad_norm": 0.1267755925655365,
      "learning_rate": 2.3629351678132166e-05,
      "loss": 0.1211,
      "step": 2530
    },
    {
      "epoch": 1.5884928080050031,
      "grad_norm": 0.4649522304534912,
      "learning_rate": 2.3525119866583282e-05,
      "loss": 0.016,
      "step": 2540
    },
    {
      "epoch": 1.5947467166979363,
      "grad_norm": 0.05075368285179138,
      "learning_rate": 2.34208880550344e-05,
      "loss": 0.1347,
      "step": 2550
    },
    {
      "epoch": 1.6010006253908693,
      "grad_norm": 0.19798973202705383,
      "learning_rate": 2.3316656243485512e-05,
      "loss": 0.1272,
      "step": 2560
    },
    {
      "epoch": 1.6072545340838023,
      "grad_norm": 15.904496192932129,
      "learning_rate": 2.321242443193663e-05,
      "loss": 0.1195,
      "step": 2570
    },
    {
      "epoch": 1.6135084427767354,
      "grad_norm": 0.9865089058876038,
      "learning_rate": 2.3108192620387745e-05,
      "loss": 0.0658,
      "step": 2580
    },
    {
      "epoch": 1.6197623514696686,
      "grad_norm": 0.7278792858123779,
      "learning_rate": 2.300396080883886e-05,
      "loss": 0.0387,
      "step": 2590
    },
    {
      "epoch": 1.6260162601626016,
      "grad_norm": 8.343572616577148,
      "learning_rate": 2.2899728997289975e-05,
      "loss": 0.1783,
      "step": 2600
    },
    {
      "epoch": 1.6322701688555346,
      "grad_norm": 0.17786404490470886,
      "learning_rate": 2.279549718574109e-05,
      "loss": 0.1297,
      "step": 2610
    },
    {
      "epoch": 1.6385240775484677,
      "grad_norm": 0.2445105016231537,
      "learning_rate": 2.2691265374192205e-05,
      "loss": 0.1792,
      "step": 2620
    },
    {
      "epoch": 1.644777986241401,
      "grad_norm": 0.3991906940937042,
      "learning_rate": 2.258703356264332e-05,
      "loss": 0.1109,
      "step": 2630
    },
    {
      "epoch": 1.6510318949343339,
      "grad_norm": 16.85204315185547,
      "learning_rate": 2.2482801751094435e-05,
      "loss": 0.0553,
      "step": 2640
    },
    {
      "epoch": 1.657285803627267,
      "grad_norm": 0.6507587432861328,
      "learning_rate": 2.2378569939545552e-05,
      "loss": 0.0877,
      "step": 2650
    },
    {
      "epoch": 1.6635397123202003,
      "grad_norm": 0.8281304240226746,
      "learning_rate": 2.2274338127996665e-05,
      "loss": 0.021,
      "step": 2660
    },
    {
      "epoch": 1.6697936210131332,
      "grad_norm": 6.584444522857666,
      "learning_rate": 2.217010631644778e-05,
      "loss": 0.0465,
      "step": 2670
    },
    {
      "epoch": 1.6760475297060662,
      "grad_norm": 0.07537899911403656,
      "learning_rate": 2.2065874504898895e-05,
      "loss": 0.0603,
      "step": 2680
    },
    {
      "epoch": 1.6823014383989994,
      "grad_norm": 17.866968154907227,
      "learning_rate": 2.196164269335001e-05,
      "loss": 0.0468,
      "step": 2690
    },
    {
      "epoch": 1.6885553470919326,
      "grad_norm": 0.08060269802808762,
      "learning_rate": 2.1857410881801128e-05,
      "loss": 0.0891,
      "step": 2700
    },
    {
      "epoch": 1.6948092557848655,
      "grad_norm": 0.08026513457298279,
      "learning_rate": 2.175317907025224e-05,
      "loss": 0.0473,
      "step": 2710
    },
    {
      "epoch": 1.7010631644777985,
      "grad_norm": 6.778684139251709,
      "learning_rate": 2.1648947258703355e-05,
      "loss": 0.0923,
      "step": 2720
    },
    {
      "epoch": 1.7073170731707317,
      "grad_norm": 9.659918785095215,
      "learning_rate": 2.1544715447154475e-05,
      "loss": 0.0679,
      "step": 2730
    },
    {
      "epoch": 1.7135709818636649,
      "grad_norm": 25.7305965423584,
      "learning_rate": 2.1440483635605588e-05,
      "loss": 0.1035,
      "step": 2740
    },
    {
      "epoch": 1.7198248905565978,
      "grad_norm": 4.740624904632568,
      "learning_rate": 2.13362518240567e-05,
      "loss": 0.0832,
      "step": 2750
    },
    {
      "epoch": 1.726078799249531,
      "grad_norm": 0.3726472854614258,
      "learning_rate": 2.123202001250782e-05,
      "loss": 0.0847,
      "step": 2760
    },
    {
      "epoch": 1.7323327079424642,
      "grad_norm": 2.4983396530151367,
      "learning_rate": 2.1127788200958934e-05,
      "loss": 0.0535,
      "step": 2770
    },
    {
      "epoch": 1.7385866166353972,
      "grad_norm": 0.2709619104862213,
      "learning_rate": 2.1023556389410048e-05,
      "loss": 0.0428,
      "step": 2780
    },
    {
      "epoch": 1.7448405253283301,
      "grad_norm": 10.534539222717285,
      "learning_rate": 2.0919324577861164e-05,
      "loss": 0.1857,
      "step": 2790
    },
    {
      "epoch": 1.7510944340212633,
      "grad_norm": 1.5311353206634521,
      "learning_rate": 2.081509276631228e-05,
      "loss": 0.1405,
      "step": 2800
    },
    {
      "epoch": 1.7573483427141965,
      "grad_norm": 0.09128742665052414,
      "learning_rate": 2.0710860954763394e-05,
      "loss": 0.054,
      "step": 2810
    },
    {
      "epoch": 1.7636022514071295,
      "grad_norm": 0.07677879929542542,
      "learning_rate": 2.060662914321451e-05,
      "loss": 0.0921,
      "step": 2820
    },
    {
      "epoch": 1.7698561601000624,
      "grad_norm": 4.500062465667725,
      "learning_rate": 2.0502397331665627e-05,
      "loss": 0.0732,
      "step": 2830
    },
    {
      "epoch": 1.7761100687929956,
      "grad_norm": 8.949225425720215,
      "learning_rate": 2.039816552011674e-05,
      "loss": 0.0695,
      "step": 2840
    },
    {
      "epoch": 1.7823639774859288,
      "grad_norm": 0.06878305226564407,
      "learning_rate": 2.0293933708567854e-05,
      "loss": 0.1072,
      "step": 2850
    },
    {
      "epoch": 1.7886178861788617,
      "grad_norm": 0.7438960671424866,
      "learning_rate": 2.018970189701897e-05,
      "loss": 0.0538,
      "step": 2860
    },
    {
      "epoch": 1.7948717948717947,
      "grad_norm": 12.813776016235352,
      "learning_rate": 2.0085470085470087e-05,
      "loss": 0.0586,
      "step": 2870
    },
    {
      "epoch": 1.8011257035647281,
      "grad_norm": 0.03767913207411766,
      "learning_rate": 1.99812382739212e-05,
      "loss": 0.0863,
      "step": 2880
    },
    {
      "epoch": 1.807379612257661,
      "grad_norm": 0.03389982879161835,
      "learning_rate": 1.9877006462372317e-05,
      "loss": 0.0571,
      "step": 2890
    },
    {
      "epoch": 1.813633520950594,
      "grad_norm": 10.080598831176758,
      "learning_rate": 1.9772774650823434e-05,
      "loss": 0.0915,
      "step": 2900
    },
    {
      "epoch": 1.8198874296435272,
      "grad_norm": 4.838637828826904,
      "learning_rate": 1.9668542839274547e-05,
      "loss": 0.1506,
      "step": 2910
    },
    {
      "epoch": 1.8261413383364604,
      "grad_norm": 0.07617270946502686,
      "learning_rate": 1.9564311027725664e-05,
      "loss": 0.163,
      "step": 2920
    },
    {
      "epoch": 1.8323952470293934,
      "grad_norm": 2.7700746059417725,
      "learning_rate": 1.9460079216176777e-05,
      "loss": 0.0797,
      "step": 2930
    },
    {
      "epoch": 1.8386491557223263,
      "grad_norm": 0.9938766956329346,
      "learning_rate": 1.9355847404627894e-05,
      "loss": 0.1307,
      "step": 2940
    },
    {
      "epoch": 1.8449030644152595,
      "grad_norm": 0.1157880574464798,
      "learning_rate": 1.925161559307901e-05,
      "loss": 0.1168,
      "step": 2950
    },
    {
      "epoch": 1.8511569731081927,
      "grad_norm": 0.1460840106010437,
      "learning_rate": 1.9147383781530123e-05,
      "loss": 0.1461,
      "step": 2960
    },
    {
      "epoch": 1.8574108818011257,
      "grad_norm": 0.1620333045721054,
      "learning_rate": 1.904315196998124e-05,
      "loss": 0.0766,
      "step": 2970
    },
    {
      "epoch": 1.8636647904940586,
      "grad_norm": 0.08686767518520355,
      "learning_rate": 1.8938920158432357e-05,
      "loss": 0.0915,
      "step": 2980
    },
    {
      "epoch": 1.8699186991869918,
      "grad_norm": 0.229703888297081,
      "learning_rate": 1.883468834688347e-05,
      "loss": 0.098,
      "step": 2990
    },
    {
      "epoch": 1.876172607879925,
      "grad_norm": 0.8074817657470703,
      "learning_rate": 1.8730456535334583e-05,
      "loss": 0.1335,
      "step": 3000
    },
    {
      "epoch": 1.882426516572858,
      "grad_norm": 0.2722013294696808,
      "learning_rate": 1.86262247237857e-05,
      "loss": 0.046,
      "step": 3010
    },
    {
      "epoch": 1.8886804252657912,
      "grad_norm": 8.586812973022461,
      "learning_rate": 1.8521992912236816e-05,
      "loss": 0.1232,
      "step": 3020
    },
    {
      "epoch": 1.8949343339587243,
      "grad_norm": 0.06670204550027847,
      "learning_rate": 1.841776110068793e-05,
      "loss": 0.0528,
      "step": 3030
    },
    {
      "epoch": 1.9011882426516573,
      "grad_norm": 0.16074185073375702,
      "learning_rate": 1.8313529289139046e-05,
      "loss": 0.0159,
      "step": 3040
    },
    {
      "epoch": 1.9074421513445903,
      "grad_norm": 0.150889590382576,
      "learning_rate": 1.8209297477590163e-05,
      "loss": 0.068,
      "step": 3050
    },
    {
      "epoch": 1.9136960600375235,
      "grad_norm": 6.567229270935059,
      "learning_rate": 1.8105065666041276e-05,
      "loss": 0.1712,
      "step": 3060
    },
    {
      "epoch": 1.9199499687304566,
      "grad_norm": 0.18101075291633606,
      "learning_rate": 1.800083385449239e-05,
      "loss": 0.1235,
      "step": 3070
    },
    {
      "epoch": 1.9262038774233896,
      "grad_norm": 0.4023401439189911,
      "learning_rate": 1.789660204294351e-05,
      "loss": 0.0974,
      "step": 3080
    },
    {
      "epoch": 1.9324577861163226,
      "grad_norm": 4.3390092849731445,
      "learning_rate": 1.7792370231394623e-05,
      "loss": 0.0334,
      "step": 3090
    },
    {
      "epoch": 1.9387116948092558,
      "grad_norm": 0.2189558893442154,
      "learning_rate": 1.7688138419845736e-05,
      "loss": 0.0159,
      "step": 3100
    },
    {
      "epoch": 1.944965603502189,
      "grad_norm": 0.18300659954547882,
      "learning_rate": 1.7583906608296853e-05,
      "loss": 0.08,
      "step": 3110
    },
    {
      "epoch": 1.951219512195122,
      "grad_norm": 10.743593215942383,
      "learning_rate": 1.747967479674797e-05,
      "loss": 0.1069,
      "step": 3120
    },
    {
      "epoch": 1.9574734208880549,
      "grad_norm": 2.026268482208252,
      "learning_rate": 1.7375442985199082e-05,
      "loss": 0.1486,
      "step": 3130
    },
    {
      "epoch": 1.9637273295809883,
      "grad_norm": 0.0737457275390625,
      "learning_rate": 1.72712111736502e-05,
      "loss": 0.0944,
      "step": 3140
    },
    {
      "epoch": 1.9699812382739212,
      "grad_norm": 11.659198760986328,
      "learning_rate": 1.7166979362101316e-05,
      "loss": 0.0488,
      "step": 3150
    },
    {
      "epoch": 1.9762351469668542,
      "grad_norm": 0.12197858095169067,
      "learning_rate": 1.706274755055243e-05,
      "loss": 0.0459,
      "step": 3160
    },
    {
      "epoch": 1.9824890556597874,
      "grad_norm": 15.860309600830078,
      "learning_rate": 1.6958515739003546e-05,
      "loss": 0.1157,
      "step": 3170
    },
    {
      "epoch": 1.9887429643527206,
      "grad_norm": 2.1709988117218018,
      "learning_rate": 1.685428392745466e-05,
      "loss": 0.0974,
      "step": 3180
    },
    {
      "epoch": 1.9949968730456535,
      "grad_norm": 0.0550648458302021,
      "learning_rate": 1.6750052115905776e-05,
      "loss": 0.0569,
      "step": 3190
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9596433599249179,
      "eval_loss": 0.15561935305595398,
      "eval_runtime": 9.6202,
      "eval_samples_per_second": 664.54,
      "eval_steps_per_second": 41.579,
      "step": 3198
    },
    {
      "epoch": 2.0012507817385865,
      "grad_norm": 3.2331981658935547,
      "learning_rate": 1.6645820304356892e-05,
      "loss": 0.0477,
      "step": 3200
    },
    {
      "epoch": 2.00750469043152,
      "grad_norm": 6.20647668838501,
      "learning_rate": 1.6541588492808005e-05,
      "loss": 0.056,
      "step": 3210
    },
    {
      "epoch": 2.013758599124453,
      "grad_norm": 6.366413116455078,
      "learning_rate": 1.6437356681259122e-05,
      "loss": 0.0355,
      "step": 3220
    },
    {
      "epoch": 2.020012507817386,
      "grad_norm": 12.342520713806152,
      "learning_rate": 1.6333124869710235e-05,
      "loss": 0.0514,
      "step": 3230
    },
    {
      "epoch": 2.026266416510319,
      "grad_norm": 8.181368827819824,
      "learning_rate": 1.6228893058161352e-05,
      "loss": 0.1135,
      "step": 3240
    },
    {
      "epoch": 2.032520325203252,
      "grad_norm": 0.05859403312206268,
      "learning_rate": 1.6124661246612465e-05,
      "loss": 0.0764,
      "step": 3250
    },
    {
      "epoch": 2.038774233896185,
      "grad_norm": 0.14892779290676117,
      "learning_rate": 1.6020429435063582e-05,
      "loss": 0.0544,
      "step": 3260
    },
    {
      "epoch": 2.045028142589118,
      "grad_norm": 15.7837553024292,
      "learning_rate": 1.59161976235147e-05,
      "loss": 0.0943,
      "step": 3270
    },
    {
      "epoch": 2.051282051282051,
      "grad_norm": 0.6360840797424316,
      "learning_rate": 1.581196581196581e-05,
      "loss": 0.1299,
      "step": 3280
    },
    {
      "epoch": 2.0575359599749845,
      "grad_norm": 0.12149184942245483,
      "learning_rate": 1.570773400041693e-05,
      "loss": 0.0081,
      "step": 3290
    },
    {
      "epoch": 2.0637898686679175,
      "grad_norm": 0.26740673184394836,
      "learning_rate": 1.5603502188868045e-05,
      "loss": 0.0802,
      "step": 3300
    },
    {
      "epoch": 2.0700437773608504,
      "grad_norm": 5.216019630432129,
      "learning_rate": 1.5499270377319158e-05,
      "loss": 0.114,
      "step": 3310
    },
    {
      "epoch": 2.076297686053784,
      "grad_norm": 1.9447969198226929,
      "learning_rate": 1.539503856577027e-05,
      "loss": 0.1569,
      "step": 3320
    },
    {
      "epoch": 2.082551594746717,
      "grad_norm": 0.06567296385765076,
      "learning_rate": 1.529080675422139e-05,
      "loss": 0.0633,
      "step": 3330
    },
    {
      "epoch": 2.0888055034396498,
      "grad_norm": 5.8874359130859375,
      "learning_rate": 1.5186574942672505e-05,
      "loss": 0.1142,
      "step": 3340
    },
    {
      "epoch": 2.0950594121325827,
      "grad_norm": 0.12224011868238449,
      "learning_rate": 1.508234313112362e-05,
      "loss": 0.0674,
      "step": 3350
    },
    {
      "epoch": 2.101313320825516,
      "grad_norm": 0.10425163060426712,
      "learning_rate": 1.4978111319574733e-05,
      "loss": 0.0498,
      "step": 3360
    },
    {
      "epoch": 2.107567229518449,
      "grad_norm": 0.8512520790100098,
      "learning_rate": 1.4873879508025851e-05,
      "loss": 0.0082,
      "step": 3370
    },
    {
      "epoch": 2.113821138211382,
      "grad_norm": 0.13858841359615326,
      "learning_rate": 1.4769647696476966e-05,
      "loss": 0.076,
      "step": 3380
    },
    {
      "epoch": 2.120075046904315,
      "grad_norm": 0.20889483392238617,
      "learning_rate": 1.466541588492808e-05,
      "loss": 0.0794,
      "step": 3390
    },
    {
      "epoch": 2.1263289555972484,
      "grad_norm": 6.3581438064575195,
      "learning_rate": 1.4561184073379198e-05,
      "loss": 0.1844,
      "step": 3400
    },
    {
      "epoch": 2.1325828642901814,
      "grad_norm": 9.88874626159668,
      "learning_rate": 1.4456952261830311e-05,
      "loss": 0.0907,
      "step": 3410
    },
    {
      "epoch": 2.1388367729831144,
      "grad_norm": 0.0884067490696907,
      "learning_rate": 1.4352720450281426e-05,
      "loss": 0.0157,
      "step": 3420
    },
    {
      "epoch": 2.1450906816760473,
      "grad_norm": 0.09208805859088898,
      "learning_rate": 1.4248488638732541e-05,
      "loss": 0.1145,
      "step": 3430
    },
    {
      "epoch": 2.1513445903689807,
      "grad_norm": 0.268216609954834,
      "learning_rate": 1.4144256827183658e-05,
      "loss": 0.0887,
      "step": 3440
    },
    {
      "epoch": 2.1575984990619137,
      "grad_norm": 16.62356185913086,
      "learning_rate": 1.4040025015634772e-05,
      "loss": 0.0435,
      "step": 3450
    },
    {
      "epoch": 2.1638524077548467,
      "grad_norm": 3.6622486114501953,
      "learning_rate": 1.3935793204085887e-05,
      "loss": 0.0675,
      "step": 3460
    },
    {
      "epoch": 2.17010631644778,
      "grad_norm": 18.517684936523438,
      "learning_rate": 1.3831561392537004e-05,
      "loss": 0.06,
      "step": 3470
    },
    {
      "epoch": 2.176360225140713,
      "grad_norm": 20.191091537475586,
      "learning_rate": 1.3727329580988119e-05,
      "loss": 0.1392,
      "step": 3480
    },
    {
      "epoch": 2.182614133833646,
      "grad_norm": 0.0838591530919075,
      "learning_rate": 1.3623097769439234e-05,
      "loss": 0.1035,
      "step": 3490
    },
    {
      "epoch": 2.188868042526579,
      "grad_norm": 0.48896852135658264,
      "learning_rate": 1.3518865957890347e-05,
      "loss": 0.0113,
      "step": 3500
    },
    {
      "epoch": 2.1951219512195124,
      "grad_norm": 0.11905106902122498,
      "learning_rate": 1.3414634146341466e-05,
      "loss": 0.095,
      "step": 3510
    },
    {
      "epoch": 2.2013758599124453,
      "grad_norm": 0.031003419309854507,
      "learning_rate": 1.3310402334792579e-05,
      "loss": 0.1348,
      "step": 3520
    },
    {
      "epoch": 2.2076297686053783,
      "grad_norm": 0.05783231556415558,
      "learning_rate": 1.3206170523243694e-05,
      "loss": 0.0482,
      "step": 3530
    },
    {
      "epoch": 2.2138836772983113,
      "grad_norm": 0.0621124766767025,
      "learning_rate": 1.310193871169481e-05,
      "loss": 0.1023,
      "step": 3540
    },
    {
      "epoch": 2.2201375859912447,
      "grad_norm": 0.3492427170276642,
      "learning_rate": 1.2997706900145925e-05,
      "loss": 0.035,
      "step": 3550
    },
    {
      "epoch": 2.2263914946841776,
      "grad_norm": 0.16736210882663727,
      "learning_rate": 1.289347508859704e-05,
      "loss": 0.0605,
      "step": 3560
    },
    {
      "epoch": 2.2326454033771106,
      "grad_norm": 2.451115846633911,
      "learning_rate": 1.2789243277048155e-05,
      "loss": 0.0965,
      "step": 3570
    },
    {
      "epoch": 2.2388993120700436,
      "grad_norm": 0.16604340076446533,
      "learning_rate": 1.2685011465499272e-05,
      "loss": 0.0042,
      "step": 3580
    },
    {
      "epoch": 2.245153220762977,
      "grad_norm": 0.2488134801387787,
      "learning_rate": 1.2580779653950387e-05,
      "loss": 0.0438,
      "step": 3590
    },
    {
      "epoch": 2.25140712945591,
      "grad_norm": 1.7930092811584473,
      "learning_rate": 1.2476547842401502e-05,
      "loss": 0.0536,
      "step": 3600
    },
    {
      "epoch": 2.257661038148843,
      "grad_norm": 0.3804109990596771,
      "learning_rate": 1.2372316030852617e-05,
      "loss": 0.109,
      "step": 3610
    },
    {
      "epoch": 2.2639149468417763,
      "grad_norm": 0.043958649039268494,
      "learning_rate": 1.2268084219303733e-05,
      "loss": 0.0149,
      "step": 3620
    },
    {
      "epoch": 2.2701688555347093,
      "grad_norm": 0.23633219301700592,
      "learning_rate": 1.2163852407754846e-05,
      "loss": 0.0825,
      "step": 3630
    },
    {
      "epoch": 2.2764227642276422,
      "grad_norm": 0.23040355741977692,
      "learning_rate": 1.2059620596205963e-05,
      "loss": 0.0471,
      "step": 3640
    },
    {
      "epoch": 2.282676672920575,
      "grad_norm": 24.810087203979492,
      "learning_rate": 1.1955388784657078e-05,
      "loss": 0.1158,
      "step": 3650
    },
    {
      "epoch": 2.2889305816135086,
      "grad_norm": 6.640023708343506,
      "learning_rate": 1.1851156973108193e-05,
      "loss": 0.0324,
      "step": 3660
    },
    {
      "epoch": 2.2951844903064416,
      "grad_norm": 7.504084587097168,
      "learning_rate": 1.1746925161559308e-05,
      "loss": 0.1002,
      "step": 3670
    },
    {
      "epoch": 2.3014383989993745,
      "grad_norm": 11.917231559753418,
      "learning_rate": 1.1642693350010425e-05,
      "loss": 0.1004,
      "step": 3680
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 0.07688772678375244,
      "learning_rate": 1.153846153846154e-05,
      "loss": 0.0185,
      "step": 3690
    },
    {
      "epoch": 2.313946216385241,
      "grad_norm": 0.32381847500801086,
      "learning_rate": 1.1434229726912654e-05,
      "loss": 0.0487,
      "step": 3700
    },
    {
      "epoch": 2.320200125078174,
      "grad_norm": 2.351641893386841,
      "learning_rate": 1.132999791536377e-05,
      "loss": 0.0924,
      "step": 3710
    },
    {
      "epoch": 2.326454033771107,
      "grad_norm": 0.7242898344993591,
      "learning_rate": 1.1225766103814884e-05,
      "loss": 0.0256,
      "step": 3720
    },
    {
      "epoch": 2.3327079424640402,
      "grad_norm": 0.036357082426548004,
      "learning_rate": 1.1121534292266001e-05,
      "loss": 0.0023,
      "step": 3730
    },
    {
      "epoch": 2.338961851156973,
      "grad_norm": 10.767958641052246,
      "learning_rate": 1.1017302480717114e-05,
      "loss": 0.0939,
      "step": 3740
    },
    {
      "epoch": 2.345215759849906,
      "grad_norm": 0.3150014877319336,
      "learning_rate": 1.0913070669168231e-05,
      "loss": 0.1504,
      "step": 3750
    },
    {
      "epoch": 2.351469668542839,
      "grad_norm": 19.857046127319336,
      "learning_rate": 1.0808838857619346e-05,
      "loss": 0.1121,
      "step": 3760
    },
    {
      "epoch": 2.3577235772357725,
      "grad_norm": 0.07913260906934738,
      "learning_rate": 1.070460704607046e-05,
      "loss": 0.0522,
      "step": 3770
    },
    {
      "epoch": 2.3639774859287055,
      "grad_norm": 0.05367664992809296,
      "learning_rate": 1.0600375234521577e-05,
      "loss": 0.107,
      "step": 3780
    },
    {
      "epoch": 2.3702313946216385,
      "grad_norm": 13.367349624633789,
      "learning_rate": 1.0496143422972692e-05,
      "loss": 0.0842,
      "step": 3790
    },
    {
      "epoch": 2.3764853033145714,
      "grad_norm": 0.9829505085945129,
      "learning_rate": 1.0391911611423807e-05,
      "loss": 0.0306,
      "step": 3800
    },
    {
      "epoch": 2.382739212007505,
      "grad_norm": 14.959074974060059,
      "learning_rate": 1.0287679799874922e-05,
      "loss": 0.0532,
      "step": 3810
    },
    {
      "epoch": 2.388993120700438,
      "grad_norm": 0.08865965902805328,
      "learning_rate": 1.0183447988326037e-05,
      "loss": 0.0834,
      "step": 3820
    },
    {
      "epoch": 2.3952470293933708,
      "grad_norm": 0.04684147238731384,
      "learning_rate": 1.0079216176777152e-05,
      "loss": 0.1351,
      "step": 3830
    },
    {
      "epoch": 2.401500938086304,
      "grad_norm": 3.9784035682678223,
      "learning_rate": 9.974984365228269e-06,
      "loss": 0.1474,
      "step": 3840
    },
    {
      "epoch": 2.407754846779237,
      "grad_norm": 35.45424270629883,
      "learning_rate": 9.870752553679384e-06,
      "loss": 0.09,
      "step": 3850
    },
    {
      "epoch": 2.41400875547217,
      "grad_norm": 0.09645674377679825,
      "learning_rate": 9.766520742130499e-06,
      "loss": 0.091,
      "step": 3860
    },
    {
      "epoch": 2.420262664165103,
      "grad_norm": 9.76945972442627,
      "learning_rate": 9.662288930581615e-06,
      "loss": 0.0698,
      "step": 3870
    },
    {
      "epoch": 2.4265165728580365,
      "grad_norm": 3.4715707302093506,
      "learning_rate": 9.558057119032729e-06,
      "loss": 0.0066,
      "step": 3880
    },
    {
      "epoch": 2.4327704815509694,
      "grad_norm": 0.3088608682155609,
      "learning_rate": 9.453825307483845e-06,
      "loss": 0.0537,
      "step": 3890
    },
    {
      "epoch": 2.4390243902439024,
      "grad_norm": 17.2441463470459,
      "learning_rate": 9.34959349593496e-06,
      "loss": 0.1071,
      "step": 3900
    },
    {
      "epoch": 2.4452782989368353,
      "grad_norm": 14.840725898742676,
      "learning_rate": 9.245361684386075e-06,
      "loss": 0.1574,
      "step": 3910
    },
    {
      "epoch": 2.4515322076297688,
      "grad_norm": 7.9365715980529785,
      "learning_rate": 9.14112987283719e-06,
      "loss": 0.1493,
      "step": 3920
    },
    {
      "epoch": 2.4577861163227017,
      "grad_norm": 15.248489379882812,
      "learning_rate": 9.036898061288305e-06,
      "loss": 0.0939,
      "step": 3930
    },
    {
      "epoch": 2.4640400250156347,
      "grad_norm": 0.07058528065681458,
      "learning_rate": 8.932666249739422e-06,
      "loss": 0.0548,
      "step": 3940
    },
    {
      "epoch": 2.470293933708568,
      "grad_norm": 6.9473066329956055,
      "learning_rate": 8.828434438190536e-06,
      "loss": 0.0996,
      "step": 3950
    },
    {
      "epoch": 2.476547842401501,
      "grad_norm": 0.025917908176779747,
      "learning_rate": 8.724202626641651e-06,
      "loss": 0.0496,
      "step": 3960
    },
    {
      "epoch": 2.482801751094434,
      "grad_norm": 0.644241988658905,
      "learning_rate": 8.619970815092766e-06,
      "loss": 0.084,
      "step": 3970
    },
    {
      "epoch": 2.489055659787367,
      "grad_norm": 9.767495155334473,
      "learning_rate": 8.515739003543883e-06,
      "loss": 0.0604,
      "step": 3980
    },
    {
      "epoch": 2.4953095684803,
      "grad_norm": 10.62019157409668,
      "learning_rate": 8.411507191994996e-06,
      "loss": 0.0913,
      "step": 3990
    },
    {
      "epoch": 2.5015634771732334,
      "grad_norm": 0.06630580872297287,
      "learning_rate": 8.307275380446113e-06,
      "loss": 0.042,
      "step": 4000
    },
    {
      "epoch": 2.5078173858661663,
      "grad_norm": 0.13579966127872467,
      "learning_rate": 8.203043568897228e-06,
      "loss": 0.1688,
      "step": 4010
    },
    {
      "epoch": 2.5140712945590993,
      "grad_norm": 14.872428894042969,
      "learning_rate": 8.098811757348343e-06,
      "loss": 0.0482,
      "step": 4020
    },
    {
      "epoch": 2.5203252032520327,
      "grad_norm": 0.1715426743030548,
      "learning_rate": 7.99457994579946e-06,
      "loss": 0.0811,
      "step": 4030
    },
    {
      "epoch": 2.5265791119449656,
      "grad_norm": 0.26075249910354614,
      "learning_rate": 7.890348134250573e-06,
      "loss": 0.0116,
      "step": 4040
    },
    {
      "epoch": 2.5328330206378986,
      "grad_norm": 25.859384536743164,
      "learning_rate": 7.78611632270169e-06,
      "loss": 0.1094,
      "step": 4050
    },
    {
      "epoch": 2.539086929330832,
      "grad_norm": 0.10087341070175171,
      "learning_rate": 7.681884511152804e-06,
      "loss": 0.0098,
      "step": 4060
    },
    {
      "epoch": 2.545340838023765,
      "grad_norm": 0.09783223271369934,
      "learning_rate": 7.57765269960392e-06,
      "loss": 0.054,
      "step": 4070
    },
    {
      "epoch": 2.551594746716698,
      "grad_norm": 0.04571198672056198,
      "learning_rate": 7.473420888055034e-06,
      "loss": 0.0122,
      "step": 4080
    },
    {
      "epoch": 2.557848655409631,
      "grad_norm": 0.05878639221191406,
      "learning_rate": 7.36918907650615e-06,
      "loss": 0.0223,
      "step": 4090
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 0.08702439069747925,
      "learning_rate": 7.264957264957266e-06,
      "loss": 0.0041,
      "step": 4100
    },
    {
      "epoch": 2.5703564727954973,
      "grad_norm": 0.7657219171524048,
      "learning_rate": 7.160725453408381e-06,
      "loss": 0.0806,
      "step": 4110
    },
    {
      "epoch": 2.5766103814884302,
      "grad_norm": 4.676258087158203,
      "learning_rate": 7.0564936418594964e-06,
      "loss": 0.1326,
      "step": 4120
    },
    {
      "epoch": 2.582864290181363,
      "grad_norm": 0.06121981143951416,
      "learning_rate": 6.9522618303106105e-06,
      "loss": 0.0405,
      "step": 4130
    },
    {
      "epoch": 2.5891181988742966,
      "grad_norm": 0.32288920879364014,
      "learning_rate": 6.848030018761726e-06,
      "loss": 0.0935,
      "step": 4140
    },
    {
      "epoch": 2.5953721075672296,
      "grad_norm": 0.055543623864650726,
      "learning_rate": 6.743798207212841e-06,
      "loss": 0.0479,
      "step": 4150
    },
    {
      "epoch": 2.6016260162601625,
      "grad_norm": 2.3875160217285156,
      "learning_rate": 6.639566395663957e-06,
      "loss": 0.1056,
      "step": 4160
    },
    {
      "epoch": 2.607879924953096,
      "grad_norm": 0.19741860032081604,
      "learning_rate": 6.535334584115073e-06,
      "loss": 0.136,
      "step": 4170
    },
    {
      "epoch": 2.614133833646029,
      "grad_norm": 10.337579727172852,
      "learning_rate": 6.431102772566188e-06,
      "loss": 0.0341,
      "step": 4180
    },
    {
      "epoch": 2.620387742338962,
      "grad_norm": 16.78190040588379,
      "learning_rate": 6.3268709610173036e-06,
      "loss": 0.1158,
      "step": 4190
    },
    {
      "epoch": 2.626641651031895,
      "grad_norm": 0.11530162394046783,
      "learning_rate": 6.222639149468418e-06,
      "loss": 0.0128,
      "step": 4200
    },
    {
      "epoch": 2.632895559724828,
      "grad_norm": 2.9177801609039307,
      "learning_rate": 6.1184073379195334e-06,
      "loss": 0.1079,
      "step": 4210
    },
    {
      "epoch": 2.639149468417761,
      "grad_norm": 0.3950444757938385,
      "learning_rate": 6.014175526370649e-06,
      "loss": 0.0377,
      "step": 4220
    },
    {
      "epoch": 2.645403377110694,
      "grad_norm": 16.018993377685547,
      "learning_rate": 5.909943714821764e-06,
      "loss": 0.0818,
      "step": 4230
    },
    {
      "epoch": 2.651657285803627,
      "grad_norm": 0.0761406272649765,
      "learning_rate": 5.805711903272879e-06,
      "loss": 0.0542,
      "step": 4240
    },
    {
      "epoch": 2.6579111944965605,
      "grad_norm": 0.026337016373872757,
      "learning_rate": 5.701480091723994e-06,
      "loss": 0.0106,
      "step": 4250
    },
    {
      "epoch": 2.6641651031894935,
      "grad_norm": 1.9637794494628906,
      "learning_rate": 5.59724828017511e-06,
      "loss": 0.1088,
      "step": 4260
    },
    {
      "epoch": 2.6704190118824265,
      "grad_norm": 0.7952378392219543,
      "learning_rate": 5.493016468626225e-06,
      "loss": 0.0964,
      "step": 4270
    },
    {
      "epoch": 2.6766729205753594,
      "grad_norm": 3.381026268005371,
      "learning_rate": 5.38878465707734e-06,
      "loss": 0.0525,
      "step": 4280
    },
    {
      "epoch": 2.682926829268293,
      "grad_norm": 0.43342188000679016,
      "learning_rate": 5.2845528455284555e-06,
      "loss": 0.0151,
      "step": 4290
    },
    {
      "epoch": 2.689180737961226,
      "grad_norm": 0.18805506825447083,
      "learning_rate": 5.180321033979571e-06,
      "loss": 0.062,
      "step": 4300
    },
    {
      "epoch": 2.6954346466541588,
      "grad_norm": 0.17551685869693756,
      "learning_rate": 5.076089222430686e-06,
      "loss": 0.0936,
      "step": 4310
    },
    {
      "epoch": 2.7016885553470917,
      "grad_norm": 14.03941535949707,
      "learning_rate": 4.971857410881801e-06,
      "loss": 0.0505,
      "step": 4320
    },
    {
      "epoch": 2.707942464040025,
      "grad_norm": 0.05037255212664604,
      "learning_rate": 4.867625599332917e-06,
      "loss": 0.0759,
      "step": 4330
    },
    {
      "epoch": 2.714196372732958,
      "grad_norm": 0.04966669902205467,
      "learning_rate": 4.763393787784032e-06,
      "loss": 0.1444,
      "step": 4340
    },
    {
      "epoch": 2.720450281425891,
      "grad_norm": 15.8434419631958,
      "learning_rate": 4.659161976235147e-06,
      "loss": 0.0453,
      "step": 4350
    },
    {
      "epoch": 2.7267041901188245,
      "grad_norm": 0.6757830381393433,
      "learning_rate": 4.554930164686262e-06,
      "loss": 0.0092,
      "step": 4360
    },
    {
      "epoch": 2.7329580988117574,
      "grad_norm": 0.04733071103692055,
      "learning_rate": 4.4506983531373784e-06,
      "loss": 0.1581,
      "step": 4370
    },
    {
      "epoch": 2.7392120075046904,
      "grad_norm": 10.390641212463379,
      "learning_rate": 4.346466541588493e-06,
      "loss": 0.0774,
      "step": 4380
    },
    {
      "epoch": 2.7454659161976234,
      "grad_norm": 8.64797306060791,
      "learning_rate": 4.242234730039608e-06,
      "loss": 0.0466,
      "step": 4390
    },
    {
      "epoch": 2.7517198248905563,
      "grad_norm": 0.4776945412158966,
      "learning_rate": 4.138002918490723e-06,
      "loss": 0.1134,
      "step": 4400
    },
    {
      "epoch": 2.7579737335834897,
      "grad_norm": 0.04566933587193489,
      "learning_rate": 4.033771106941839e-06,
      "loss": 0.0257,
      "step": 4410
    },
    {
      "epoch": 2.7642276422764227,
      "grad_norm": 1.387783408164978,
      "learning_rate": 3.929539295392954e-06,
      "loss": 0.0547,
      "step": 4420
    },
    {
      "epoch": 2.7704815509693557,
      "grad_norm": 29.414443969726562,
      "learning_rate": 3.825307483844069e-06,
      "loss": 0.1279,
      "step": 4430
    },
    {
      "epoch": 2.776735459662289,
      "grad_norm": 0.04681648686528206,
      "learning_rate": 3.7210756722951843e-06,
      "loss": 0.0623,
      "step": 4440
    },
    {
      "epoch": 2.782989368355222,
      "grad_norm": 0.09161368012428284,
      "learning_rate": 3.6168438607463e-06,
      "loss": 0.0326,
      "step": 4450
    },
    {
      "epoch": 2.789243277048155,
      "grad_norm": 0.03261221945285797,
      "learning_rate": 3.5126120491974155e-06,
      "loss": 0.1025,
      "step": 4460
    },
    {
      "epoch": 2.7954971857410884,
      "grad_norm": 8.571043968200684,
      "learning_rate": 3.408380237648531e-06,
      "loss": 0.0982,
      "step": 4470
    },
    {
      "epoch": 2.8017510944340214,
      "grad_norm": 16.645267486572266,
      "learning_rate": 3.3041484260996458e-06,
      "loss": 0.092,
      "step": 4480
    },
    {
      "epoch": 2.8080050031269543,
      "grad_norm": 0.18340611457824707,
      "learning_rate": 3.199916614550761e-06,
      "loss": 0.0606,
      "step": 4490
    },
    {
      "epoch": 2.8142589118198873,
      "grad_norm": 14.378385543823242,
      "learning_rate": 3.095684803001876e-06,
      "loss": 0.1024,
      "step": 4500
    },
    {
      "epoch": 2.8205128205128203,
      "grad_norm": 0.4862397611141205,
      "learning_rate": 2.991452991452992e-06,
      "loss": 0.0036,
      "step": 4510
    },
    {
      "epoch": 2.8267667292057537,
      "grad_norm": 0.7361537218093872,
      "learning_rate": 2.887221179904107e-06,
      "loss": 0.1036,
      "step": 4520
    },
    {
      "epoch": 2.8330206378986866,
      "grad_norm": 0.08632861077785492,
      "learning_rate": 2.782989368355222e-06,
      "loss": 0.0289,
      "step": 4530
    },
    {
      "epoch": 2.8392745465916196,
      "grad_norm": 0.3896108567714691,
      "learning_rate": 2.678757556806337e-06,
      "loss": 0.1135,
      "step": 4540
    },
    {
      "epoch": 2.845528455284553,
      "grad_norm": 9.706189155578613,
      "learning_rate": 2.574525745257453e-06,
      "loss": 0.0717,
      "step": 4550
    },
    {
      "epoch": 2.851782363977486,
      "grad_norm": 25.46244239807129,
      "learning_rate": 2.470293933708568e-06,
      "loss": 0.11,
      "step": 4560
    },
    {
      "epoch": 2.858036272670419,
      "grad_norm": 0.021783405914902687,
      "learning_rate": 2.366062122159683e-06,
      "loss": 0.0233,
      "step": 4570
    },
    {
      "epoch": 2.8642901813633523,
      "grad_norm": 4.645816326141357,
      "learning_rate": 2.2618303106107986e-06,
      "loss": 0.0884,
      "step": 4580
    },
    {
      "epoch": 2.8705440900562853,
      "grad_norm": 0.04999960958957672,
      "learning_rate": 2.157598499061914e-06,
      "loss": 0.1176,
      "step": 4590
    },
    {
      "epoch": 2.8767979987492183,
      "grad_norm": 20.302082061767578,
      "learning_rate": 2.0533666875130293e-06,
      "loss": 0.0762,
      "step": 4600
    },
    {
      "epoch": 2.8830519074421512,
      "grad_norm": 0.22758091986179352,
      "learning_rate": 1.9491348759641442e-06,
      "loss": 0.1487,
      "step": 4610
    },
    {
      "epoch": 2.889305816135084,
      "grad_norm": 0.10643687844276428,
      "learning_rate": 1.8449030644152594e-06,
      "loss": 0.0472,
      "step": 4620
    },
    {
      "epoch": 2.8955597248280176,
      "grad_norm": 0.41473498940467834,
      "learning_rate": 1.740671252866375e-06,
      "loss": 0.0516,
      "step": 4630
    },
    {
      "epoch": 2.9018136335209506,
      "grad_norm": 0.05504235625267029,
      "learning_rate": 1.6364394413174901e-06,
      "loss": 0.1006,
      "step": 4640
    },
    {
      "epoch": 2.9080675422138835,
      "grad_norm": 17.76020050048828,
      "learning_rate": 1.5322076297686055e-06,
      "loss": 0.0093,
      "step": 4650
    },
    {
      "epoch": 2.914321450906817,
      "grad_norm": 0.04617204889655113,
      "learning_rate": 1.4279758182197209e-06,
      "loss": 0.0532,
      "step": 4660
    },
    {
      "epoch": 2.92057535959975,
      "grad_norm": 10.263123512268066,
      "learning_rate": 1.323744006670836e-06,
      "loss": 0.0597,
      "step": 4670
    },
    {
      "epoch": 2.926829268292683,
      "grad_norm": 0.14105966687202454,
      "learning_rate": 1.2195121951219514e-06,
      "loss": 0.0159,
      "step": 4680
    },
    {
      "epoch": 2.9330831769856163,
      "grad_norm": 0.1503136157989502,
      "learning_rate": 1.1152803835730665e-06,
      "loss": 0.0334,
      "step": 4690
    },
    {
      "epoch": 2.9393370856785492,
      "grad_norm": 35.3747673034668,
      "learning_rate": 1.0110485720241819e-06,
      "loss": 0.1314,
      "step": 4700
    },
    {
      "epoch": 2.945590994371482,
      "grad_norm": 6.0265398025512695,
      "learning_rate": 9.06816760475297e-07,
      "loss": 0.0339,
      "step": 4710
    },
    {
      "epoch": 2.951844903064415,
      "grad_norm": 12.885842323303223,
      "learning_rate": 8.025849489264124e-07,
      "loss": 0.041,
      "step": 4720
    },
    {
      "epoch": 2.958098811757348,
      "grad_norm": 0.1301533430814743,
      "learning_rate": 6.983531373775277e-07,
      "loss": 0.0421,
      "step": 4730
    },
    {
      "epoch": 2.9643527204502815,
      "grad_norm": 0.7874271869659424,
      "learning_rate": 5.941213258286429e-07,
      "loss": 0.0033,
      "step": 4740
    },
    {
      "epoch": 2.9706066291432145,
      "grad_norm": 0.04366769641637802,
      "learning_rate": 4.898895142797583e-07,
      "loss": 0.0213,
      "step": 4750
    },
    {
      "epoch": 2.9768605378361475,
      "grad_norm": 0.0487026646733284,
      "learning_rate": 3.856577027308735e-07,
      "loss": 0.0073,
      "step": 4760
    },
    {
      "epoch": 2.983114446529081,
      "grad_norm": 0.04167275130748749,
      "learning_rate": 2.8142589118198876e-07,
      "loss": 0.1071,
      "step": 4770
    },
    {
      "epoch": 2.989368355222014,
      "grad_norm": 6.685578346252441,
      "learning_rate": 1.7719407963310404e-07,
      "loss": 0.1126,
      "step": 4780
    },
    {
      "epoch": 2.995622263914947,
      "grad_norm": 11.813361167907715,
      "learning_rate": 7.29622680842193e-08,
      "loss": 0.0894,
      "step": 4790
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9596433599249179,
      "eval_loss": 0.16424718499183655,
      "eval_runtime": 9.8432,
      "eval_samples_per_second": 649.481,
      "eval_steps_per_second": 40.637,
      "step": 4797
    }
  ],
  "logging_steps": 10,
  "max_steps": 4797,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 24363812344320.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
